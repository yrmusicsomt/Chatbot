{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yrmusicsomt/Chatbot/blob/main/Lab_2B_Neural_Network_for_Simple_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0ukgcX3pjTC",
        "outputId": "2c7cc230-5cf4-44e7-b017-cde2c4456a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 43.5344, Weight: 0.1579, Bias: 0.7864\n",
            "Epoch 1, Loss: 25.9123, Weight: 0.4890, Bias: 0.8787\n",
            "Epoch 2, Loss: 15.4601, Weight: 0.7440, Bias: 0.9493\n",
            "Epoch 3, Loss: 9.2604, Weight: 0.9406, Bias: 1.0032\n",
            "Epoch 4, Loss: 5.5830, Weight: 1.0922, Bias: 1.0442\n",
            "Epoch 5, Loss: 3.4016, Weight: 1.2090, Bias: 1.0752\n",
            "Epoch 6, Loss: 2.1076, Weight: 1.2991, Bias: 1.0987\n",
            "Epoch 7, Loss: 1.3399, Weight: 1.3687, Bias: 1.1163\n",
            "Epoch 8, Loss: 0.8844, Weight: 1.4224, Bias: 1.1293\n",
            "Epoch 9, Loss: 0.6140, Weight: 1.4639, Bias: 1.1389\n",
            "Epoch 10, Loss: 0.4534, Weight: 1.4960, Bias: 1.1458\n",
            "Epoch 11, Loss: 0.3580, Weight: 1.5208, Bias: 1.1506\n",
            "Epoch 12, Loss: 0.3012, Weight: 1.5401, Bias: 1.1538\n",
            "Epoch 13, Loss: 0.2673, Weight: 1.5551, Bias: 1.1559\n",
            "Epoch 14, Loss: 0.2470, Weight: 1.5668, Bias: 1.1569\n",
            "Epoch 15, Loss: 0.2348, Weight: 1.5759, Bias: 1.1573\n",
            "Epoch 16, Loss: 0.2273, Weight: 1.5831, Bias: 1.1571\n",
            "Epoch 17, Loss: 0.2227, Weight: 1.5887, Bias: 1.1565\n",
            "Epoch 18, Loss: 0.2198, Weight: 1.5932, Bias: 1.1555\n",
            "Epoch 19, Loss: 0.2179, Weight: 1.5968, Bias: 1.1543\n",
            "Epoch 20, Loss: 0.2166, Weight: 1.5997, Bias: 1.1529\n",
            "Epoch 21, Loss: 0.2156, Weight: 1.6021, Bias: 1.1514\n",
            "Epoch 22, Loss: 0.2149, Weight: 1.6040, Bias: 1.1497\n",
            "Epoch 23, Loss: 0.2142, Weight: 1.6057, Bias: 1.1480\n",
            "Epoch 24, Loss: 0.2137, Weight: 1.6071, Bias: 1.1462\n",
            "Epoch 25, Loss: 0.2132, Weight: 1.6083, Bias: 1.1443\n",
            "Epoch 26, Loss: 0.2127, Weight: 1.6093, Bias: 1.1425\n",
            "Epoch 27, Loss: 0.2122, Weight: 1.6103, Bias: 1.1405\n",
            "Epoch 28, Loss: 0.2118, Weight: 1.6111, Bias: 1.1386\n",
            "Epoch 29, Loss: 0.2113, Weight: 1.6119, Bias: 1.1367\n",
            "Epoch 30, Loss: 0.2109, Weight: 1.6127, Bias: 1.1347\n",
            "Epoch 31, Loss: 0.2104, Weight: 1.6134, Bias: 1.1328\n",
            "Epoch 32, Loss: 0.2100, Weight: 1.6140, Bias: 1.1308\n",
            "Epoch 33, Loss: 0.2096, Weight: 1.6147, Bias: 1.1289\n",
            "Epoch 34, Loss: 0.2092, Weight: 1.6153, Bias: 1.1269\n",
            "Epoch 35, Loss: 0.2087, Weight: 1.6159, Bias: 1.1249\n",
            "Epoch 36, Loss: 0.2083, Weight: 1.6165, Bias: 1.1230\n",
            "Epoch 37, Loss: 0.2079, Weight: 1.6171, Bias: 1.1210\n",
            "Epoch 38, Loss: 0.2075, Weight: 1.6177, Bias: 1.1191\n",
            "Epoch 39, Loss: 0.2071, Weight: 1.6183, Bias: 1.1171\n",
            "Epoch 40, Loss: 0.2067, Weight: 1.6188, Bias: 1.1152\n",
            "Epoch 41, Loss: 0.2063, Weight: 1.6194, Bias: 1.1133\n",
            "Epoch 42, Loss: 0.2059, Weight: 1.6199, Bias: 1.1113\n",
            "Epoch 43, Loss: 0.2055, Weight: 1.6205, Bias: 1.1094\n",
            "Epoch 44, Loss: 0.2051, Weight: 1.6211, Bias: 1.1075\n",
            "Epoch 45, Loss: 0.2047, Weight: 1.6216, Bias: 1.1056\n",
            "Epoch 46, Loss: 0.2043, Weight: 1.6222, Bias: 1.1037\n",
            "Epoch 47, Loss: 0.2039, Weight: 1.6227, Bias: 1.1018\n",
            "Epoch 48, Loss: 0.2035, Weight: 1.6232, Bias: 1.0999\n",
            "Epoch 49, Loss: 0.2031, Weight: 1.6238, Bias: 1.0980\n",
            "Epoch 50, Loss: 0.2027, Weight: 1.6243, Bias: 1.0961\n",
            "Epoch 51, Loss: 0.2023, Weight: 1.6249, Bias: 1.0942\n",
            "Epoch 52, Loss: 0.2019, Weight: 1.6254, Bias: 1.0923\n",
            "Epoch 53, Loss: 0.2016, Weight: 1.6259, Bias: 1.0905\n",
            "Epoch 54, Loss: 0.2012, Weight: 1.6265, Bias: 1.0886\n",
            "Epoch 55, Loss: 0.2008, Weight: 1.6270, Bias: 1.0867\n",
            "Epoch 56, Loss: 0.2004, Weight: 1.6275, Bias: 1.0849\n",
            "Epoch 57, Loss: 0.2001, Weight: 1.6281, Bias: 1.0830\n",
            "Epoch 58, Loss: 0.1997, Weight: 1.6286, Bias: 1.0812\n",
            "Epoch 59, Loss: 0.1993, Weight: 1.6291, Bias: 1.0794\n",
            "Epoch 60, Loss: 0.1989, Weight: 1.6296, Bias: 1.0775\n",
            "Epoch 61, Loss: 0.1986, Weight: 1.6302, Bias: 1.0757\n",
            "Epoch 62, Loss: 0.1982, Weight: 1.6307, Bias: 1.0739\n",
            "Epoch 63, Loss: 0.1979, Weight: 1.6312, Bias: 1.0720\n",
            "Epoch 64, Loss: 0.1975, Weight: 1.6317, Bias: 1.0702\n",
            "Epoch 65, Loss: 0.1972, Weight: 1.6322, Bias: 1.0684\n",
            "Epoch 66, Loss: 0.1968, Weight: 1.6328, Bias: 1.0666\n",
            "Epoch 67, Loss: 0.1964, Weight: 1.6333, Bias: 1.0648\n",
            "Epoch 68, Loss: 0.1961, Weight: 1.6338, Bias: 1.0630\n",
            "Epoch 69, Loss: 0.1957, Weight: 1.6343, Bias: 1.0612\n",
            "Epoch 70, Loss: 0.1954, Weight: 1.6348, Bias: 1.0595\n",
            "Epoch 71, Loss: 0.1951, Weight: 1.6353, Bias: 1.0577\n",
            "Epoch 72, Loss: 0.1947, Weight: 1.6358, Bias: 1.0559\n",
            "Epoch 73, Loss: 0.1944, Weight: 1.6363, Bias: 1.0541\n",
            "Epoch 74, Loss: 0.1940, Weight: 1.6368, Bias: 1.0524\n",
            "Epoch 75, Loss: 0.1937, Weight: 1.6373, Bias: 1.0506\n",
            "Epoch 76, Loss: 0.1934, Weight: 1.6378, Bias: 1.0489\n",
            "Epoch 77, Loss: 0.1930, Weight: 1.6383, Bias: 1.0471\n",
            "Epoch 78, Loss: 0.1927, Weight: 1.6388, Bias: 1.0454\n",
            "Epoch 79, Loss: 0.1924, Weight: 1.6393, Bias: 1.0436\n",
            "Epoch 80, Loss: 0.1921, Weight: 1.6398, Bias: 1.0419\n",
            "Epoch 81, Loss: 0.1917, Weight: 1.6403, Bias: 1.0402\n",
            "Epoch 82, Loss: 0.1914, Weight: 1.6408, Bias: 1.0385\n",
            "Epoch 83, Loss: 0.1911, Weight: 1.6413, Bias: 1.0367\n",
            "Epoch 84, Loss: 0.1908, Weight: 1.6418, Bias: 1.0350\n",
            "Epoch 85, Loss: 0.1905, Weight: 1.6423, Bias: 1.0333\n",
            "Epoch 86, Loss: 0.1901, Weight: 1.6428, Bias: 1.0316\n",
            "Epoch 87, Loss: 0.1898, Weight: 1.6433, Bias: 1.0299\n",
            "Epoch 88, Loss: 0.1895, Weight: 1.6437, Bias: 1.0282\n",
            "Epoch 89, Loss: 0.1892, Weight: 1.6442, Bias: 1.0265\n",
            "Epoch 90, Loss: 0.1889, Weight: 1.6447, Bias: 1.0248\n",
            "Epoch 91, Loss: 0.1886, Weight: 1.6452, Bias: 1.0232\n",
            "Epoch 92, Loss: 0.1883, Weight: 1.6457, Bias: 1.0215\n",
            "Epoch 93, Loss: 0.1880, Weight: 1.6461, Bias: 1.0198\n",
            "Epoch 94, Loss: 0.1877, Weight: 1.6466, Bias: 1.0182\n",
            "Epoch 95, Loss: 0.1874, Weight: 1.6471, Bias: 1.0165\n",
            "Epoch 96, Loss: 0.1871, Weight: 1.6476, Bias: 1.0148\n",
            "Epoch 97, Loss: 0.1868, Weight: 1.6480, Bias: 1.0132\n",
            "Epoch 98, Loss: 0.1865, Weight: 1.6485, Bias: 1.0115\n",
            "Epoch 99, Loss: 0.1862, Weight: 1.6490, Bias: 1.0099\n",
            "Epoch 100, Loss: 0.1859, Weight: 1.6494, Bias: 1.0083\n",
            "Epoch 101, Loss: 0.1856, Weight: 1.6499, Bias: 1.0066\n",
            "Epoch 102, Loss: 0.1853, Weight: 1.6504, Bias: 1.0050\n",
            "Epoch 103, Loss: 0.1850, Weight: 1.6508, Bias: 1.0034\n",
            "Epoch 104, Loss: 0.1848, Weight: 1.6513, Bias: 1.0018\n",
            "Epoch 105, Loss: 0.1845, Weight: 1.6518, Bias: 1.0002\n",
            "Epoch 106, Loss: 0.1842, Weight: 1.6522, Bias: 0.9985\n",
            "Epoch 107, Loss: 0.1839, Weight: 1.6527, Bias: 0.9969\n",
            "Epoch 108, Loss: 0.1836, Weight: 1.6531, Bias: 0.9953\n",
            "Epoch 109, Loss: 0.1834, Weight: 1.6536, Bias: 0.9937\n",
            "Epoch 110, Loss: 0.1831, Weight: 1.6541, Bias: 0.9922\n",
            "Epoch 111, Loss: 0.1828, Weight: 1.6545, Bias: 0.9906\n",
            "Epoch 112, Loss: 0.1825, Weight: 1.6550, Bias: 0.9890\n",
            "Epoch 113, Loss: 0.1823, Weight: 1.6554, Bias: 0.9874\n",
            "Epoch 114, Loss: 0.1820, Weight: 1.6559, Bias: 0.9858\n",
            "Epoch 115, Loss: 0.1817, Weight: 1.6563, Bias: 0.9843\n",
            "Epoch 116, Loss: 0.1815, Weight: 1.6568, Bias: 0.9827\n",
            "Epoch 117, Loss: 0.1812, Weight: 1.6572, Bias: 0.9811\n",
            "Epoch 118, Loss: 0.1809, Weight: 1.6576, Bias: 0.9796\n",
            "Epoch 119, Loss: 0.1807, Weight: 1.6581, Bias: 0.9780\n",
            "Epoch 120, Loss: 0.1804, Weight: 1.6585, Bias: 0.9765\n",
            "Epoch 121, Loss: 0.1802, Weight: 1.6590, Bias: 0.9750\n",
            "Epoch 122, Loss: 0.1799, Weight: 1.6594, Bias: 0.9734\n",
            "Epoch 123, Loss: 0.1797, Weight: 1.6598, Bias: 0.9719\n",
            "Epoch 124, Loss: 0.1794, Weight: 1.6603, Bias: 0.9704\n",
            "Epoch 125, Loss: 0.1791, Weight: 1.6607, Bias: 0.9688\n",
            "Epoch 126, Loss: 0.1789, Weight: 1.6612, Bias: 0.9673\n",
            "Epoch 127, Loss: 0.1786, Weight: 1.6616, Bias: 0.9658\n",
            "Epoch 128, Loss: 0.1784, Weight: 1.6620, Bias: 0.9643\n",
            "Epoch 129, Loss: 0.1782, Weight: 1.6625, Bias: 0.9628\n",
            "Epoch 130, Loss: 0.1779, Weight: 1.6629, Bias: 0.9613\n",
            "Epoch 131, Loss: 0.1777, Weight: 1.6633, Bias: 0.9598\n",
            "Epoch 132, Loss: 0.1774, Weight: 1.6637, Bias: 0.9583\n",
            "Epoch 133, Loss: 0.1772, Weight: 1.6642, Bias: 0.9568\n",
            "Epoch 134, Loss: 0.1769, Weight: 1.6646, Bias: 0.9553\n",
            "Epoch 135, Loss: 0.1767, Weight: 1.6650, Bias: 0.9538\n",
            "Epoch 136, Loss: 0.1765, Weight: 1.6654, Bias: 0.9523\n",
            "Epoch 137, Loss: 0.1762, Weight: 1.6659, Bias: 0.9509\n",
            "Epoch 138, Loss: 0.1760, Weight: 1.6663, Bias: 0.9494\n",
            "Epoch 139, Loss: 0.1758, Weight: 1.6667, Bias: 0.9479\n",
            "Epoch 140, Loss: 0.1755, Weight: 1.6671, Bias: 0.9465\n",
            "Epoch 141, Loss: 0.1753, Weight: 1.6675, Bias: 0.9450\n",
            "Epoch 142, Loss: 0.1751, Weight: 1.6679, Bias: 0.9436\n",
            "Epoch 143, Loss: 0.1748, Weight: 1.6684, Bias: 0.9421\n",
            "Epoch 144, Loss: 0.1746, Weight: 1.6688, Bias: 0.9407\n",
            "Epoch 145, Loss: 0.1744, Weight: 1.6692, Bias: 0.9392\n",
            "Epoch 146, Loss: 0.1742, Weight: 1.6696, Bias: 0.9378\n",
            "Epoch 147, Loss: 0.1739, Weight: 1.6700, Bias: 0.9364\n",
            "Epoch 148, Loss: 0.1737, Weight: 1.6704, Bias: 0.9349\n",
            "Epoch 149, Loss: 0.1735, Weight: 1.6708, Bias: 0.9335\n",
            "Epoch 150, Loss: 0.1733, Weight: 1.6712, Bias: 0.9321\n",
            "Epoch 151, Loss: 0.1731, Weight: 1.6716, Bias: 0.9307\n",
            "Epoch 152, Loss: 0.1728, Weight: 1.6720, Bias: 0.9293\n",
            "Epoch 153, Loss: 0.1726, Weight: 1.6724, Bias: 0.9279\n",
            "Epoch 154, Loss: 0.1724, Weight: 1.6728, Bias: 0.9265\n",
            "Epoch 155, Loss: 0.1722, Weight: 1.6732, Bias: 0.9251\n",
            "Epoch 156, Loss: 0.1720, Weight: 1.6736, Bias: 0.9237\n",
            "Epoch 157, Loss: 0.1718, Weight: 1.6740, Bias: 0.9223\n",
            "Epoch 158, Loss: 0.1716, Weight: 1.6744, Bias: 0.9209\n",
            "Epoch 159, Loss: 0.1714, Weight: 1.6748, Bias: 0.9195\n",
            "Epoch 160, Loss: 0.1712, Weight: 1.6752, Bias: 0.9181\n",
            "Epoch 161, Loss: 0.1710, Weight: 1.6756, Bias: 0.9168\n",
            "Epoch 162, Loss: 0.1707, Weight: 1.6760, Bias: 0.9154\n",
            "Epoch 163, Loss: 0.1705, Weight: 1.6764, Bias: 0.9140\n",
            "Epoch 164, Loss: 0.1703, Weight: 1.6768, Bias: 0.9126\n",
            "Epoch 165, Loss: 0.1701, Weight: 1.6772, Bias: 0.9113\n",
            "Epoch 166, Loss: 0.1699, Weight: 1.6776, Bias: 0.9099\n",
            "Epoch 167, Loss: 0.1697, Weight: 1.6779, Bias: 0.9086\n",
            "Epoch 168, Loss: 0.1695, Weight: 1.6783, Bias: 0.9072\n",
            "Epoch 169, Loss: 0.1694, Weight: 1.6787, Bias: 0.9059\n",
            "Epoch 170, Loss: 0.1692, Weight: 1.6791, Bias: 0.9045\n",
            "Epoch 171, Loss: 0.1690, Weight: 1.6795, Bias: 0.9032\n",
            "Epoch 172, Loss: 0.1688, Weight: 1.6799, Bias: 0.9019\n",
            "Epoch 173, Loss: 0.1686, Weight: 1.6802, Bias: 0.9005\n",
            "Epoch 174, Loss: 0.1684, Weight: 1.6806, Bias: 0.8992\n",
            "Epoch 175, Loss: 0.1682, Weight: 1.6810, Bias: 0.8979\n",
            "Epoch 176, Loss: 0.1680, Weight: 1.6814, Bias: 0.8966\n",
            "Epoch 177, Loss: 0.1678, Weight: 1.6818, Bias: 0.8953\n",
            "Epoch 178, Loss: 0.1676, Weight: 1.6821, Bias: 0.8940\n",
            "Epoch 179, Loss: 0.1674, Weight: 1.6825, Bias: 0.8926\n",
            "Epoch 180, Loss: 0.1673, Weight: 1.6829, Bias: 0.8913\n",
            "Epoch 181, Loss: 0.1671, Weight: 1.6832, Bias: 0.8900\n",
            "Epoch 182, Loss: 0.1669, Weight: 1.6836, Bias: 0.8887\n",
            "Epoch 183, Loss: 0.1667, Weight: 1.6840, Bias: 0.8875\n",
            "Epoch 184, Loss: 0.1665, Weight: 1.6844, Bias: 0.8862\n",
            "Epoch 185, Loss: 0.1664, Weight: 1.6847, Bias: 0.8849\n",
            "Epoch 186, Loss: 0.1662, Weight: 1.6851, Bias: 0.8836\n",
            "Epoch 187, Loss: 0.1660, Weight: 1.6855, Bias: 0.8823\n",
            "Epoch 188, Loss: 0.1658, Weight: 1.6858, Bias: 0.8811\n",
            "Epoch 189, Loss: 0.1656, Weight: 1.6862, Bias: 0.8798\n",
            "Epoch 190, Loss: 0.1655, Weight: 1.6865, Bias: 0.8785\n",
            "Epoch 191, Loss: 0.1653, Weight: 1.6869, Bias: 0.8773\n",
            "Epoch 192, Loss: 0.1651, Weight: 1.6873, Bias: 0.8760\n",
            "Epoch 193, Loss: 0.1650, Weight: 1.6876, Bias: 0.8747\n",
            "Epoch 194, Loss: 0.1648, Weight: 1.6880, Bias: 0.8735\n",
            "Epoch 195, Loss: 0.1646, Weight: 1.6883, Bias: 0.8722\n",
            "Epoch 196, Loss: 0.1644, Weight: 1.6887, Bias: 0.8710\n",
            "Epoch 197, Loss: 0.1643, Weight: 1.6891, Bias: 0.8697\n",
            "Epoch 198, Loss: 0.1641, Weight: 1.6894, Bias: 0.8685\n",
            "Epoch 199, Loss: 0.1639, Weight: 1.6898, Bias: 0.8673\n",
            "Epoch 200, Loss: 0.1638, Weight: 1.6901, Bias: 0.8660\n",
            "Epoch 201, Loss: 0.1636, Weight: 1.6905, Bias: 0.8648\n",
            "Epoch 202, Loss: 0.1635, Weight: 1.6908, Bias: 0.8636\n",
            "Epoch 203, Loss: 0.1633, Weight: 1.6912, Bias: 0.8624\n",
            "Epoch 204, Loss: 0.1631, Weight: 1.6915, Bias: 0.8612\n",
            "Epoch 205, Loss: 0.1630, Weight: 1.6919, Bias: 0.8599\n",
            "Epoch 206, Loss: 0.1628, Weight: 1.6922, Bias: 0.8587\n",
            "Epoch 207, Loss: 0.1627, Weight: 1.6925, Bias: 0.8575\n",
            "Epoch 208, Loss: 0.1625, Weight: 1.6929, Bias: 0.8563\n",
            "Epoch 209, Loss: 0.1623, Weight: 1.6932, Bias: 0.8551\n",
            "Epoch 210, Loss: 0.1622, Weight: 1.6936, Bias: 0.8539\n",
            "Epoch 211, Loss: 0.1620, Weight: 1.6939, Bias: 0.8527\n",
            "Epoch 212, Loss: 0.1619, Weight: 1.6943, Bias: 0.8515\n",
            "Epoch 213, Loss: 0.1617, Weight: 1.6946, Bias: 0.8504\n",
            "Epoch 214, Loss: 0.1616, Weight: 1.6949, Bias: 0.8492\n",
            "Epoch 215, Loss: 0.1614, Weight: 1.6953, Bias: 0.8480\n",
            "Epoch 216, Loss: 0.1613, Weight: 1.6956, Bias: 0.8468\n",
            "Epoch 217, Loss: 0.1611, Weight: 1.6959, Bias: 0.8456\n",
            "Epoch 218, Loss: 0.1610, Weight: 1.6963, Bias: 0.8445\n",
            "Epoch 219, Loss: 0.1608, Weight: 1.6966, Bias: 0.8433\n",
            "Epoch 220, Loss: 0.1607, Weight: 1.6969, Bias: 0.8421\n",
            "Epoch 221, Loss: 0.1605, Weight: 1.6973, Bias: 0.8410\n",
            "Epoch 222, Loss: 0.1604, Weight: 1.6976, Bias: 0.8398\n",
            "Epoch 223, Loss: 0.1602, Weight: 1.6979, Bias: 0.8387\n",
            "Epoch 224, Loss: 0.1601, Weight: 1.6983, Bias: 0.8375\n",
            "Epoch 225, Loss: 0.1600, Weight: 1.6986, Bias: 0.8364\n",
            "Epoch 226, Loss: 0.1598, Weight: 1.6989, Bias: 0.8352\n",
            "Epoch 227, Loss: 0.1597, Weight: 1.6992, Bias: 0.8341\n",
            "Epoch 228, Loss: 0.1595, Weight: 1.6996, Bias: 0.8330\n",
            "Epoch 229, Loss: 0.1594, Weight: 1.6999, Bias: 0.8318\n",
            "Epoch 230, Loss: 0.1593, Weight: 1.7002, Bias: 0.8307\n",
            "Epoch 231, Loss: 0.1591, Weight: 1.7005, Bias: 0.8296\n",
            "Epoch 232, Loss: 0.1590, Weight: 1.7009, Bias: 0.8284\n",
            "Epoch 233, Loss: 0.1588, Weight: 1.7012, Bias: 0.8273\n",
            "Epoch 234, Loss: 0.1587, Weight: 1.7015, Bias: 0.8262\n",
            "Epoch 235, Loss: 0.1586, Weight: 1.7018, Bias: 0.8251\n",
            "Epoch 236, Loss: 0.1584, Weight: 1.7021, Bias: 0.8240\n",
            "Epoch 237, Loss: 0.1583, Weight: 1.7025, Bias: 0.8229\n",
            "Epoch 238, Loss: 0.1582, Weight: 1.7028, Bias: 0.8218\n",
            "Epoch 239, Loss: 0.1580, Weight: 1.7031, Bias: 0.8207\n",
            "Epoch 240, Loss: 0.1579, Weight: 1.7034, Bias: 0.8196\n",
            "Epoch 241, Loss: 0.1578, Weight: 1.7037, Bias: 0.8185\n",
            "Epoch 242, Loss: 0.1577, Weight: 1.7040, Bias: 0.8174\n",
            "Epoch 243, Loss: 0.1575, Weight: 1.7043, Bias: 0.8163\n",
            "Epoch 244, Loss: 0.1574, Weight: 1.7046, Bias: 0.8152\n",
            "Epoch 245, Loss: 0.1573, Weight: 1.7050, Bias: 0.8141\n",
            "Epoch 246, Loss: 0.1571, Weight: 1.7053, Bias: 0.8130\n",
            "Epoch 247, Loss: 0.1570, Weight: 1.7056, Bias: 0.8120\n",
            "Epoch 248, Loss: 0.1569, Weight: 1.7059, Bias: 0.8109\n",
            "Epoch 249, Loss: 0.1568, Weight: 1.7062, Bias: 0.8098\n",
            "Epoch 250, Loss: 0.1566, Weight: 1.7065, Bias: 0.8088\n",
            "Epoch 251, Loss: 0.1565, Weight: 1.7068, Bias: 0.8077\n",
            "Epoch 252, Loss: 0.1564, Weight: 1.7071, Bias: 0.8066\n",
            "Epoch 253, Loss: 0.1563, Weight: 1.7074, Bias: 0.8056\n",
            "Epoch 254, Loss: 0.1562, Weight: 1.7077, Bias: 0.8045\n",
            "Epoch 255, Loss: 0.1560, Weight: 1.7080, Bias: 0.8035\n",
            "Epoch 256, Loss: 0.1559, Weight: 1.7083, Bias: 0.8024\n",
            "Epoch 257, Loss: 0.1558, Weight: 1.7086, Bias: 0.8014\n",
            "Epoch 258, Loss: 0.1557, Weight: 1.7089, Bias: 0.8003\n",
            "Epoch 259, Loss: 0.1556, Weight: 1.7092, Bias: 0.7993\n",
            "Epoch 260, Loss: 0.1554, Weight: 1.7095, Bias: 0.7983\n",
            "Epoch 261, Loss: 0.1553, Weight: 1.7098, Bias: 0.7972\n",
            "Epoch 262, Loss: 0.1552, Weight: 1.7101, Bias: 0.7962\n",
            "Epoch 263, Loss: 0.1551, Weight: 1.7104, Bias: 0.7952\n",
            "Epoch 264, Loss: 0.1550, Weight: 1.7107, Bias: 0.7941\n",
            "Epoch 265, Loss: 0.1549, Weight: 1.7110, Bias: 0.7931\n",
            "Epoch 266, Loss: 0.1548, Weight: 1.7113, Bias: 0.7921\n",
            "Epoch 267, Loss: 0.1546, Weight: 1.7115, Bias: 0.7911\n",
            "Epoch 268, Loss: 0.1545, Weight: 1.7118, Bias: 0.7901\n",
            "Epoch 269, Loss: 0.1544, Weight: 1.7121, Bias: 0.7890\n",
            "Epoch 270, Loss: 0.1543, Weight: 1.7124, Bias: 0.7880\n",
            "Epoch 271, Loss: 0.1542, Weight: 1.7127, Bias: 0.7870\n",
            "Epoch 272, Loss: 0.1541, Weight: 1.7130, Bias: 0.7860\n",
            "Epoch 273, Loss: 0.1540, Weight: 1.7133, Bias: 0.7850\n",
            "Epoch 274, Loss: 0.1539, Weight: 1.7136, Bias: 0.7840\n",
            "Epoch 275, Loss: 0.1538, Weight: 1.7138, Bias: 0.7830\n",
            "Epoch 276, Loss: 0.1537, Weight: 1.7141, Bias: 0.7820\n",
            "Epoch 277, Loss: 0.1536, Weight: 1.7144, Bias: 0.7811\n",
            "Epoch 278, Loss: 0.1534, Weight: 1.7147, Bias: 0.7801\n",
            "Epoch 279, Loss: 0.1533, Weight: 1.7150, Bias: 0.7791\n",
            "Epoch 280, Loss: 0.1532, Weight: 1.7153, Bias: 0.7781\n",
            "Epoch 281, Loss: 0.1531, Weight: 1.7155, Bias: 0.7771\n",
            "Epoch 282, Loss: 0.1530, Weight: 1.7158, Bias: 0.7762\n",
            "Epoch 283, Loss: 0.1529, Weight: 1.7161, Bias: 0.7752\n",
            "Epoch 284, Loss: 0.1528, Weight: 1.7164, Bias: 0.7742\n",
            "Epoch 285, Loss: 0.1527, Weight: 1.7166, Bias: 0.7733\n",
            "Epoch 286, Loss: 0.1526, Weight: 1.7169, Bias: 0.7723\n",
            "Epoch 287, Loss: 0.1525, Weight: 1.7172, Bias: 0.7713\n",
            "Epoch 288, Loss: 0.1524, Weight: 1.7175, Bias: 0.7704\n",
            "Epoch 289, Loss: 0.1523, Weight: 1.7177, Bias: 0.7694\n",
            "Epoch 290, Loss: 0.1522, Weight: 1.7180, Bias: 0.7685\n",
            "Epoch 291, Loss: 0.1521, Weight: 1.7183, Bias: 0.7675\n",
            "Epoch 292, Loss: 0.1520, Weight: 1.7186, Bias: 0.7666\n",
            "Epoch 293, Loss: 0.1519, Weight: 1.7188, Bias: 0.7656\n",
            "Epoch 294, Loss: 0.1518, Weight: 1.7191, Bias: 0.7647\n",
            "Epoch 295, Loss: 0.1517, Weight: 1.7194, Bias: 0.7637\n",
            "Epoch 296, Loss: 0.1516, Weight: 1.7196, Bias: 0.7628\n",
            "Epoch 297, Loss: 0.1516, Weight: 1.7199, Bias: 0.7619\n",
            "Epoch 298, Loss: 0.1515, Weight: 1.7202, Bias: 0.7609\n",
            "Epoch 299, Loss: 0.1514, Weight: 1.7204, Bias: 0.7600\n",
            "Epoch 300, Loss: 0.1513, Weight: 1.7207, Bias: 0.7591\n",
            "Epoch 301, Loss: 0.1512, Weight: 1.7210, Bias: 0.7582\n",
            "Epoch 302, Loss: 0.1511, Weight: 1.7212, Bias: 0.7572\n",
            "Epoch 303, Loss: 0.1510, Weight: 1.7215, Bias: 0.7563\n",
            "Epoch 304, Loss: 0.1509, Weight: 1.7217, Bias: 0.7554\n",
            "Epoch 305, Loss: 0.1508, Weight: 1.7220, Bias: 0.7545\n",
            "Epoch 306, Loss: 0.1507, Weight: 1.7223, Bias: 0.7536\n",
            "Epoch 307, Loss: 0.1506, Weight: 1.7225, Bias: 0.7527\n",
            "Epoch 308, Loss: 0.1505, Weight: 1.7228, Bias: 0.7518\n",
            "Epoch 309, Loss: 0.1505, Weight: 1.7230, Bias: 0.7509\n",
            "Epoch 310, Loss: 0.1504, Weight: 1.7233, Bias: 0.7500\n",
            "Epoch 311, Loss: 0.1503, Weight: 1.7236, Bias: 0.7491\n",
            "Epoch 312, Loss: 0.1502, Weight: 1.7238, Bias: 0.7482\n",
            "Epoch 313, Loss: 0.1501, Weight: 1.7241, Bias: 0.7473\n",
            "Epoch 314, Loss: 0.1500, Weight: 1.7243, Bias: 0.7464\n",
            "Epoch 315, Loss: 0.1499, Weight: 1.7246, Bias: 0.7455\n",
            "Epoch 316, Loss: 0.1499, Weight: 1.7248, Bias: 0.7446\n",
            "Epoch 317, Loss: 0.1498, Weight: 1.7251, Bias: 0.7437\n",
            "Epoch 318, Loss: 0.1497, Weight: 1.7253, Bias: 0.7429\n",
            "Epoch 319, Loss: 0.1496, Weight: 1.7256, Bias: 0.7420\n",
            "Epoch 320, Loss: 0.1495, Weight: 1.7258, Bias: 0.7411\n",
            "Epoch 321, Loss: 0.1494, Weight: 1.7261, Bias: 0.7402\n",
            "Epoch 322, Loss: 0.1494, Weight: 1.7263, Bias: 0.7394\n",
            "Epoch 323, Loss: 0.1493, Weight: 1.7266, Bias: 0.7385\n",
            "Epoch 324, Loss: 0.1492, Weight: 1.7268, Bias: 0.7376\n",
            "Epoch 325, Loss: 0.1491, Weight: 1.7271, Bias: 0.7368\n",
            "Epoch 326, Loss: 0.1490, Weight: 1.7273, Bias: 0.7359\n",
            "Epoch 327, Loss: 0.1489, Weight: 1.7276, Bias: 0.7351\n",
            "Epoch 328, Loss: 0.1489, Weight: 1.7278, Bias: 0.7342\n",
            "Epoch 329, Loss: 0.1488, Weight: 1.7280, Bias: 0.7334\n",
            "Epoch 330, Loss: 0.1487, Weight: 1.7283, Bias: 0.7325\n",
            "Epoch 331, Loss: 0.1486, Weight: 1.7285, Bias: 0.7317\n",
            "Epoch 332, Loss: 0.1486, Weight: 1.7288, Bias: 0.7308\n",
            "Epoch 333, Loss: 0.1485, Weight: 1.7290, Bias: 0.7300\n",
            "Epoch 334, Loss: 0.1484, Weight: 1.7293, Bias: 0.7291\n",
            "Epoch 335, Loss: 0.1483, Weight: 1.7295, Bias: 0.7283\n",
            "Epoch 336, Loss: 0.1482, Weight: 1.7297, Bias: 0.7275\n",
            "Epoch 337, Loss: 0.1482, Weight: 1.7300, Bias: 0.7266\n",
            "Epoch 338, Loss: 0.1481, Weight: 1.7302, Bias: 0.7258\n",
            "Epoch 339, Loss: 0.1480, Weight: 1.7304, Bias: 0.7250\n",
            "Epoch 340, Loss: 0.1480, Weight: 1.7307, Bias: 0.7241\n",
            "Epoch 341, Loss: 0.1479, Weight: 1.7309, Bias: 0.7233\n",
            "Epoch 342, Loss: 0.1478, Weight: 1.7312, Bias: 0.7225\n",
            "Epoch 343, Loss: 0.1477, Weight: 1.7314, Bias: 0.7217\n",
            "Epoch 344, Loss: 0.1477, Weight: 1.7316, Bias: 0.7209\n",
            "Epoch 345, Loss: 0.1476, Weight: 1.7319, Bias: 0.7200\n",
            "Epoch 346, Loss: 0.1475, Weight: 1.7321, Bias: 0.7192\n",
            "Epoch 347, Loss: 0.1474, Weight: 1.7323, Bias: 0.7184\n",
            "Epoch 348, Loss: 0.1474, Weight: 1.7325, Bias: 0.7176\n",
            "Epoch 349, Loss: 0.1473, Weight: 1.7328, Bias: 0.7168\n",
            "Epoch 350, Loss: 0.1472, Weight: 1.7330, Bias: 0.7160\n",
            "Epoch 351, Loss: 0.1472, Weight: 1.7332, Bias: 0.7152\n",
            "Epoch 352, Loss: 0.1471, Weight: 1.7335, Bias: 0.7144\n",
            "Epoch 353, Loss: 0.1470, Weight: 1.7337, Bias: 0.7136\n",
            "Epoch 354, Loss: 0.1470, Weight: 1.7339, Bias: 0.7128\n",
            "Epoch 355, Loss: 0.1469, Weight: 1.7341, Bias: 0.7120\n",
            "Epoch 356, Loss: 0.1468, Weight: 1.7344, Bias: 0.7112\n",
            "Epoch 357, Loss: 0.1468, Weight: 1.7346, Bias: 0.7104\n",
            "Epoch 358, Loss: 0.1467, Weight: 1.7348, Bias: 0.7097\n",
            "Epoch 359, Loss: 0.1466, Weight: 1.7350, Bias: 0.7089\n",
            "Epoch 360, Loss: 0.1466, Weight: 1.7353, Bias: 0.7081\n",
            "Epoch 361, Loss: 0.1465, Weight: 1.7355, Bias: 0.7073\n",
            "Epoch 362, Loss: 0.1464, Weight: 1.7357, Bias: 0.7065\n",
            "Epoch 363, Loss: 0.1464, Weight: 1.7359, Bias: 0.7058\n",
            "Epoch 364, Loss: 0.1463, Weight: 1.7362, Bias: 0.7050\n",
            "Epoch 365, Loss: 0.1462, Weight: 1.7364, Bias: 0.7042\n",
            "Epoch 366, Loss: 0.1462, Weight: 1.7366, Bias: 0.7035\n",
            "Epoch 367, Loss: 0.1461, Weight: 1.7368, Bias: 0.7027\n",
            "Epoch 368, Loss: 0.1460, Weight: 1.7370, Bias: 0.7019\n",
            "Epoch 369, Loss: 0.1460, Weight: 1.7372, Bias: 0.7012\n",
            "Epoch 370, Loss: 0.1459, Weight: 1.7375, Bias: 0.7004\n",
            "Epoch 371, Loss: 0.1459, Weight: 1.7377, Bias: 0.6997\n",
            "Epoch 372, Loss: 0.1458, Weight: 1.7379, Bias: 0.6989\n",
            "Epoch 373, Loss: 0.1457, Weight: 1.7381, Bias: 0.6982\n",
            "Epoch 374, Loss: 0.1457, Weight: 1.7383, Bias: 0.6974\n",
            "Epoch 375, Loss: 0.1456, Weight: 1.7385, Bias: 0.6967\n",
            "Epoch 376, Loss: 0.1455, Weight: 1.7388, Bias: 0.6959\n",
            "Epoch 377, Loss: 0.1455, Weight: 1.7390, Bias: 0.6952\n",
            "Epoch 378, Loss: 0.1454, Weight: 1.7392, Bias: 0.6944\n",
            "Epoch 379, Loss: 0.1454, Weight: 1.7394, Bias: 0.6937\n",
            "Epoch 380, Loss: 0.1453, Weight: 1.7396, Bias: 0.6929\n",
            "Epoch 381, Loss: 0.1452, Weight: 1.7398, Bias: 0.6922\n",
            "Epoch 382, Loss: 0.1452, Weight: 1.7400, Bias: 0.6915\n",
            "Epoch 383, Loss: 0.1451, Weight: 1.7402, Bias: 0.6908\n",
            "Epoch 384, Loss: 0.1451, Weight: 1.7404, Bias: 0.6900\n",
            "Epoch 385, Loss: 0.1450, Weight: 1.7406, Bias: 0.6893\n",
            "Epoch 386, Loss: 0.1450, Weight: 1.7409, Bias: 0.6886\n",
            "Epoch 387, Loss: 0.1449, Weight: 1.7411, Bias: 0.6878\n",
            "Epoch 388, Loss: 0.1448, Weight: 1.7413, Bias: 0.6871\n",
            "Epoch 389, Loss: 0.1448, Weight: 1.7415, Bias: 0.6864\n",
            "Epoch 390, Loss: 0.1447, Weight: 1.7417, Bias: 0.6857\n",
            "Epoch 391, Loss: 0.1447, Weight: 1.7419, Bias: 0.6850\n",
            "Epoch 392, Loss: 0.1446, Weight: 1.7421, Bias: 0.6843\n",
            "Epoch 393, Loss: 0.1446, Weight: 1.7423, Bias: 0.6836\n",
            "Epoch 394, Loss: 0.1445, Weight: 1.7425, Bias: 0.6828\n",
            "Epoch 395, Loss: 0.1445, Weight: 1.7427, Bias: 0.6821\n",
            "Epoch 396, Loss: 0.1444, Weight: 1.7429, Bias: 0.6814\n",
            "Epoch 397, Loss: 0.1444, Weight: 1.7431, Bias: 0.6807\n",
            "Epoch 398, Loss: 0.1443, Weight: 1.7433, Bias: 0.6800\n",
            "Epoch 399, Loss: 0.1442, Weight: 1.7435, Bias: 0.6793\n",
            "Epoch 400, Loss: 0.1442, Weight: 1.7437, Bias: 0.6786\n",
            "Epoch 401, Loss: 0.1441, Weight: 1.7439, Bias: 0.6779\n",
            "Epoch 402, Loss: 0.1441, Weight: 1.7441, Bias: 0.6773\n",
            "Epoch 403, Loss: 0.1440, Weight: 1.7443, Bias: 0.6766\n",
            "Epoch 404, Loss: 0.1440, Weight: 1.7445, Bias: 0.6759\n",
            "Epoch 405, Loss: 0.1439, Weight: 1.7447, Bias: 0.6752\n",
            "Epoch 406, Loss: 0.1439, Weight: 1.7449, Bias: 0.6745\n",
            "Epoch 407, Loss: 0.1438, Weight: 1.7451, Bias: 0.6738\n",
            "Epoch 408, Loss: 0.1438, Weight: 1.7453, Bias: 0.6731\n",
            "Epoch 409, Loss: 0.1437, Weight: 1.7455, Bias: 0.6725\n",
            "Epoch 410, Loss: 0.1437, Weight: 1.7457, Bias: 0.6718\n",
            "Epoch 411, Loss: 0.1436, Weight: 1.7458, Bias: 0.6711\n",
            "Epoch 412, Loss: 0.1436, Weight: 1.7460, Bias: 0.6704\n",
            "Epoch 413, Loss: 0.1435, Weight: 1.7462, Bias: 0.6698\n",
            "Epoch 414, Loss: 0.1435, Weight: 1.7464, Bias: 0.6691\n",
            "Epoch 415, Loss: 0.1434, Weight: 1.7466, Bias: 0.6684\n",
            "Epoch 416, Loss: 0.1434, Weight: 1.7468, Bias: 0.6678\n",
            "Epoch 417, Loss: 0.1433, Weight: 1.7470, Bias: 0.6671\n",
            "Epoch 418, Loss: 0.1433, Weight: 1.7472, Bias: 0.6664\n",
            "Epoch 419, Loss: 0.1432, Weight: 1.7474, Bias: 0.6658\n",
            "Epoch 420, Loss: 0.1432, Weight: 1.7476, Bias: 0.6651\n",
            "Epoch 421, Loss: 0.1432, Weight: 1.7477, Bias: 0.6645\n",
            "Epoch 422, Loss: 0.1431, Weight: 1.7479, Bias: 0.6638\n",
            "Epoch 423, Loss: 0.1431, Weight: 1.7481, Bias: 0.6632\n",
            "Epoch 424, Loss: 0.1430, Weight: 1.7483, Bias: 0.6625\n",
            "Epoch 425, Loss: 0.1430, Weight: 1.7485, Bias: 0.6619\n",
            "Epoch 426, Loss: 0.1429, Weight: 1.7487, Bias: 0.6612\n",
            "Epoch 427, Loss: 0.1429, Weight: 1.7489, Bias: 0.6606\n",
            "Epoch 428, Loss: 0.1428, Weight: 1.7490, Bias: 0.6599\n",
            "Epoch 429, Loss: 0.1428, Weight: 1.7492, Bias: 0.6593\n",
            "Epoch 430, Loss: 0.1427, Weight: 1.7494, Bias: 0.6586\n",
            "Epoch 431, Loss: 0.1427, Weight: 1.7496, Bias: 0.6580\n",
            "Epoch 432, Loss: 0.1427, Weight: 1.7498, Bias: 0.6574\n",
            "Epoch 433, Loss: 0.1426, Weight: 1.7500, Bias: 0.6567\n",
            "Epoch 434, Loss: 0.1426, Weight: 1.7501, Bias: 0.6561\n",
            "Epoch 435, Loss: 0.1425, Weight: 1.7503, Bias: 0.6555\n",
            "Epoch 436, Loss: 0.1425, Weight: 1.7505, Bias: 0.6549\n",
            "Epoch 437, Loss: 0.1424, Weight: 1.7507, Bias: 0.6542\n",
            "Epoch 438, Loss: 0.1424, Weight: 1.7509, Bias: 0.6536\n",
            "Epoch 439, Loss: 0.1424, Weight: 1.7510, Bias: 0.6530\n",
            "Epoch 440, Loss: 0.1423, Weight: 1.7512, Bias: 0.6524\n",
            "Epoch 441, Loss: 0.1423, Weight: 1.7514, Bias: 0.6517\n",
            "Epoch 442, Loss: 0.1422, Weight: 1.7516, Bias: 0.6511\n",
            "Epoch 443, Loss: 0.1422, Weight: 1.7517, Bias: 0.6505\n",
            "Epoch 444, Loss: 0.1422, Weight: 1.7519, Bias: 0.6499\n",
            "Epoch 445, Loss: 0.1421, Weight: 1.7521, Bias: 0.6493\n",
            "Epoch 446, Loss: 0.1421, Weight: 1.7523, Bias: 0.6487\n",
            "Epoch 447, Loss: 0.1420, Weight: 1.7524, Bias: 0.6481\n",
            "Epoch 448, Loss: 0.1420, Weight: 1.7526, Bias: 0.6474\n",
            "Epoch 449, Loss: 0.1419, Weight: 1.7528, Bias: 0.6468\n",
            "Epoch 450, Loss: 0.1419, Weight: 1.7530, Bias: 0.6462\n",
            "Epoch 451, Loss: 0.1419, Weight: 1.7531, Bias: 0.6456\n",
            "Epoch 452, Loss: 0.1418, Weight: 1.7533, Bias: 0.6450\n",
            "Epoch 453, Loss: 0.1418, Weight: 1.7535, Bias: 0.6444\n",
            "Epoch 454, Loss: 0.1418, Weight: 1.7536, Bias: 0.6438\n",
            "Epoch 455, Loss: 0.1417, Weight: 1.7538, Bias: 0.6432\n",
            "Epoch 456, Loss: 0.1417, Weight: 1.7540, Bias: 0.6427\n",
            "Epoch 457, Loss: 0.1416, Weight: 1.7541, Bias: 0.6421\n",
            "Epoch 458, Loss: 0.1416, Weight: 1.7543, Bias: 0.6415\n",
            "Epoch 459, Loss: 0.1416, Weight: 1.7545, Bias: 0.6409\n",
            "Epoch 460, Loss: 0.1415, Weight: 1.7547, Bias: 0.6403\n",
            "Epoch 461, Loss: 0.1415, Weight: 1.7548, Bias: 0.6397\n",
            "Epoch 462, Loss: 0.1415, Weight: 1.7550, Bias: 0.6391\n",
            "Epoch 463, Loss: 0.1414, Weight: 1.7552, Bias: 0.6385\n",
            "Epoch 464, Loss: 0.1414, Weight: 1.7553, Bias: 0.6380\n",
            "Epoch 465, Loss: 0.1413, Weight: 1.7555, Bias: 0.6374\n",
            "Epoch 466, Loss: 0.1413, Weight: 1.7557, Bias: 0.6368\n",
            "Epoch 467, Loss: 0.1413, Weight: 1.7558, Bias: 0.6362\n",
            "Epoch 468, Loss: 0.1412, Weight: 1.7560, Bias: 0.6357\n",
            "Epoch 469, Loss: 0.1412, Weight: 1.7561, Bias: 0.6351\n",
            "Epoch 470, Loss: 0.1412, Weight: 1.7563, Bias: 0.6345\n",
            "Epoch 471, Loss: 0.1411, Weight: 1.7565, Bias: 0.6339\n",
            "Epoch 472, Loss: 0.1411, Weight: 1.7566, Bias: 0.6334\n",
            "Epoch 473, Loss: 0.1411, Weight: 1.7568, Bias: 0.6328\n",
            "Epoch 474, Loss: 0.1410, Weight: 1.7570, Bias: 0.6323\n",
            "Epoch 475, Loss: 0.1410, Weight: 1.7571, Bias: 0.6317\n",
            "Epoch 476, Loss: 0.1410, Weight: 1.7573, Bias: 0.6311\n",
            "Epoch 477, Loss: 0.1409, Weight: 1.7574, Bias: 0.6306\n",
            "Epoch 478, Loss: 0.1409, Weight: 1.7576, Bias: 0.6300\n",
            "Epoch 479, Loss: 0.1409, Weight: 1.7578, Bias: 0.6295\n",
            "Epoch 480, Loss: 0.1408, Weight: 1.7579, Bias: 0.6289\n",
            "Epoch 481, Loss: 0.1408, Weight: 1.7581, Bias: 0.6284\n",
            "Epoch 482, Loss: 0.1408, Weight: 1.7582, Bias: 0.6278\n",
            "Epoch 483, Loss: 0.1407, Weight: 1.7584, Bias: 0.6272\n",
            "Epoch 484, Loss: 0.1407, Weight: 1.7585, Bias: 0.6267\n",
            "Epoch 485, Loss: 0.1407, Weight: 1.7587, Bias: 0.6262\n",
            "Epoch 486, Loss: 0.1406, Weight: 1.7589, Bias: 0.6256\n",
            "Epoch 487, Loss: 0.1406, Weight: 1.7590, Bias: 0.6251\n",
            "Epoch 488, Loss: 0.1406, Weight: 1.7592, Bias: 0.6245\n",
            "Epoch 489, Loss: 0.1405, Weight: 1.7593, Bias: 0.6240\n",
            "Epoch 490, Loss: 0.1405, Weight: 1.7595, Bias: 0.6234\n",
            "Epoch 491, Loss: 0.1405, Weight: 1.7596, Bias: 0.6229\n",
            "Epoch 492, Loss: 0.1404, Weight: 1.7598, Bias: 0.6224\n",
            "Epoch 493, Loss: 0.1404, Weight: 1.7599, Bias: 0.6218\n",
            "Epoch 494, Loss: 0.1404, Weight: 1.7601, Bias: 0.6213\n",
            "Epoch 495, Loss: 0.1403, Weight: 1.7602, Bias: 0.6208\n",
            "Epoch 496, Loss: 0.1403, Weight: 1.7604, Bias: 0.6202\n",
            "Epoch 497, Loss: 0.1403, Weight: 1.7605, Bias: 0.6197\n",
            "Epoch 498, Loss: 0.1403, Weight: 1.7607, Bias: 0.6192\n",
            "Epoch 499, Loss: 0.1402, Weight: 1.7608, Bias: 0.6187\n",
            "Epoch 500, Loss: 0.1402, Weight: 1.7610, Bias: 0.6181\n",
            "Epoch 501, Loss: 0.1402, Weight: 1.7611, Bias: 0.6176\n",
            "Epoch 502, Loss: 0.1401, Weight: 1.7613, Bias: 0.6171\n",
            "Epoch 503, Loss: 0.1401, Weight: 1.7614, Bias: 0.6166\n",
            "Epoch 504, Loss: 0.1401, Weight: 1.7616, Bias: 0.6161\n",
            "Epoch 505, Loss: 0.1400, Weight: 1.7617, Bias: 0.6155\n",
            "Epoch 506, Loss: 0.1400, Weight: 1.7619, Bias: 0.6150\n",
            "Epoch 507, Loss: 0.1400, Weight: 1.7620, Bias: 0.6145\n",
            "Epoch 508, Loss: 0.1400, Weight: 1.7622, Bias: 0.6140\n",
            "Epoch 509, Loss: 0.1399, Weight: 1.7623, Bias: 0.6135\n",
            "Epoch 510, Loss: 0.1399, Weight: 1.7625, Bias: 0.6130\n",
            "Epoch 511, Loss: 0.1399, Weight: 1.7626, Bias: 0.6125\n",
            "Epoch 512, Loss: 0.1398, Weight: 1.7628, Bias: 0.6120\n",
            "Epoch 513, Loss: 0.1398, Weight: 1.7629, Bias: 0.6115\n",
            "Epoch 514, Loss: 0.1398, Weight: 1.7630, Bias: 0.6110\n",
            "Epoch 515, Loss: 0.1398, Weight: 1.7632, Bias: 0.6105\n",
            "Epoch 516, Loss: 0.1397, Weight: 1.7633, Bias: 0.6100\n",
            "Epoch 517, Loss: 0.1397, Weight: 1.7635, Bias: 0.6095\n",
            "Epoch 518, Loss: 0.1397, Weight: 1.7636, Bias: 0.6090\n",
            "Epoch 519, Loss: 0.1397, Weight: 1.7638, Bias: 0.6085\n",
            "Epoch 520, Loss: 0.1396, Weight: 1.7639, Bias: 0.6080\n",
            "Epoch 521, Loss: 0.1396, Weight: 1.7640, Bias: 0.6075\n",
            "Epoch 522, Loss: 0.1396, Weight: 1.7642, Bias: 0.6070\n",
            "Epoch 523, Loss: 0.1396, Weight: 1.7643, Bias: 0.6065\n",
            "Epoch 524, Loss: 0.1395, Weight: 1.7645, Bias: 0.6060\n",
            "Epoch 525, Loss: 0.1395, Weight: 1.7646, Bias: 0.6055\n",
            "Epoch 526, Loss: 0.1395, Weight: 1.7647, Bias: 0.6050\n",
            "Epoch 527, Loss: 0.1394, Weight: 1.7649, Bias: 0.6046\n",
            "Epoch 528, Loss: 0.1394, Weight: 1.7650, Bias: 0.6041\n",
            "Epoch 529, Loss: 0.1394, Weight: 1.7651, Bias: 0.6036\n",
            "Epoch 530, Loss: 0.1394, Weight: 1.7653, Bias: 0.6031\n",
            "Epoch 531, Loss: 0.1393, Weight: 1.7654, Bias: 0.6026\n",
            "Epoch 532, Loss: 0.1393, Weight: 1.7656, Bias: 0.6022\n",
            "Epoch 533, Loss: 0.1393, Weight: 1.7657, Bias: 0.6017\n",
            "Epoch 534, Loss: 0.1393, Weight: 1.7658, Bias: 0.6012\n",
            "Epoch 535, Loss: 0.1392, Weight: 1.7660, Bias: 0.6007\n",
            "Epoch 536, Loss: 0.1392, Weight: 1.7661, Bias: 0.6003\n",
            "Epoch 537, Loss: 0.1392, Weight: 1.7662, Bias: 0.5998\n",
            "Epoch 538, Loss: 0.1392, Weight: 1.7664, Bias: 0.5993\n",
            "Epoch 539, Loss: 0.1392, Weight: 1.7665, Bias: 0.5988\n",
            "Epoch 540, Loss: 0.1391, Weight: 1.7666, Bias: 0.5984\n",
            "Epoch 541, Loss: 0.1391, Weight: 1.7668, Bias: 0.5979\n",
            "Epoch 542, Loss: 0.1391, Weight: 1.7669, Bias: 0.5974\n",
            "Epoch 543, Loss: 0.1391, Weight: 1.7670, Bias: 0.5970\n",
            "Epoch 544, Loss: 0.1390, Weight: 1.7672, Bias: 0.5965\n",
            "Epoch 545, Loss: 0.1390, Weight: 1.7673, Bias: 0.5961\n",
            "Epoch 546, Loss: 0.1390, Weight: 1.7674, Bias: 0.5956\n",
            "Epoch 547, Loss: 0.1390, Weight: 1.7676, Bias: 0.5951\n",
            "Epoch 548, Loss: 0.1389, Weight: 1.7677, Bias: 0.5947\n",
            "Epoch 549, Loss: 0.1389, Weight: 1.7678, Bias: 0.5942\n",
            "Epoch 550, Loss: 0.1389, Weight: 1.7680, Bias: 0.5938\n",
            "Epoch 551, Loss: 0.1389, Weight: 1.7681, Bias: 0.5933\n",
            "Epoch 552, Loss: 0.1389, Weight: 1.7682, Bias: 0.5929\n",
            "Epoch 553, Loss: 0.1388, Weight: 1.7683, Bias: 0.5924\n",
            "Epoch 554, Loss: 0.1388, Weight: 1.7685, Bias: 0.5920\n",
            "Epoch 555, Loss: 0.1388, Weight: 1.7686, Bias: 0.5915\n",
            "Epoch 556, Loss: 0.1388, Weight: 1.7687, Bias: 0.5911\n",
            "Epoch 557, Loss: 0.1387, Weight: 1.7689, Bias: 0.5906\n",
            "Epoch 558, Loss: 0.1387, Weight: 1.7690, Bias: 0.5902\n",
            "Epoch 559, Loss: 0.1387, Weight: 1.7691, Bias: 0.5897\n",
            "Epoch 560, Loss: 0.1387, Weight: 1.7692, Bias: 0.5893\n",
            "Epoch 561, Loss: 0.1387, Weight: 1.7694, Bias: 0.5889\n",
            "Epoch 562, Loss: 0.1386, Weight: 1.7695, Bias: 0.5884\n",
            "Epoch 563, Loss: 0.1386, Weight: 1.7696, Bias: 0.5880\n",
            "Epoch 564, Loss: 0.1386, Weight: 1.7697, Bias: 0.5876\n",
            "Epoch 565, Loss: 0.1386, Weight: 1.7699, Bias: 0.5871\n",
            "Epoch 566, Loss: 0.1386, Weight: 1.7700, Bias: 0.5867\n",
            "Epoch 567, Loss: 0.1385, Weight: 1.7701, Bias: 0.5863\n",
            "Epoch 568, Loss: 0.1385, Weight: 1.7702, Bias: 0.5858\n",
            "Epoch 569, Loss: 0.1385, Weight: 1.7704, Bias: 0.5854\n",
            "Epoch 570, Loss: 0.1385, Weight: 1.7705, Bias: 0.5850\n",
            "Epoch 571, Loss: 0.1385, Weight: 1.7706, Bias: 0.5845\n",
            "Epoch 572, Loss: 0.1384, Weight: 1.7707, Bias: 0.5841\n",
            "Epoch 573, Loss: 0.1384, Weight: 1.7708, Bias: 0.5837\n",
            "Epoch 574, Loss: 0.1384, Weight: 1.7710, Bias: 0.5833\n",
            "Epoch 575, Loss: 0.1384, Weight: 1.7711, Bias: 0.5828\n",
            "Epoch 576, Loss: 0.1384, Weight: 1.7712, Bias: 0.5824\n",
            "Epoch 577, Loss: 0.1383, Weight: 1.7713, Bias: 0.5820\n",
            "Epoch 578, Loss: 0.1383, Weight: 1.7714, Bias: 0.5816\n",
            "Epoch 579, Loss: 0.1383, Weight: 1.7716, Bias: 0.5812\n",
            "Epoch 580, Loss: 0.1383, Weight: 1.7717, Bias: 0.5807\n",
            "Epoch 581, Loss: 0.1383, Weight: 1.7718, Bias: 0.5803\n",
            "Epoch 582, Loss: 0.1382, Weight: 1.7719, Bias: 0.5799\n",
            "Epoch 583, Loss: 0.1382, Weight: 1.7720, Bias: 0.5795\n",
            "Epoch 584, Loss: 0.1382, Weight: 1.7722, Bias: 0.5791\n",
            "Epoch 585, Loss: 0.1382, Weight: 1.7723, Bias: 0.5787\n",
            "Epoch 586, Loss: 0.1382, Weight: 1.7724, Bias: 0.5783\n",
            "Epoch 587, Loss: 0.1382, Weight: 1.7725, Bias: 0.5779\n",
            "Epoch 588, Loss: 0.1381, Weight: 1.7726, Bias: 0.5774\n",
            "Epoch 589, Loss: 0.1381, Weight: 1.7727, Bias: 0.5770\n",
            "Epoch 590, Loss: 0.1381, Weight: 1.7729, Bias: 0.5766\n",
            "Epoch 591, Loss: 0.1381, Weight: 1.7730, Bias: 0.5762\n",
            "Epoch 592, Loss: 0.1381, Weight: 1.7731, Bias: 0.5758\n",
            "Epoch 593, Loss: 0.1380, Weight: 1.7732, Bias: 0.5754\n",
            "Epoch 594, Loss: 0.1380, Weight: 1.7733, Bias: 0.5750\n",
            "Epoch 595, Loss: 0.1380, Weight: 1.7734, Bias: 0.5746\n",
            "Epoch 596, Loss: 0.1380, Weight: 1.7735, Bias: 0.5742\n",
            "Epoch 597, Loss: 0.1380, Weight: 1.7737, Bias: 0.5738\n",
            "Epoch 598, Loss: 0.1380, Weight: 1.7738, Bias: 0.5734\n",
            "Epoch 599, Loss: 0.1379, Weight: 1.7739, Bias: 0.5730\n",
            "Epoch 600, Loss: 0.1379, Weight: 1.7740, Bias: 0.5726\n",
            "Epoch 601, Loss: 0.1379, Weight: 1.7741, Bias: 0.5723\n",
            "Epoch 602, Loss: 0.1379, Weight: 1.7742, Bias: 0.5719\n",
            "Epoch 603, Loss: 0.1379, Weight: 1.7743, Bias: 0.5715\n",
            "Epoch 604, Loss: 0.1379, Weight: 1.7744, Bias: 0.5711\n",
            "Epoch 605, Loss: 0.1378, Weight: 1.7746, Bias: 0.5707\n",
            "Epoch 606, Loss: 0.1378, Weight: 1.7747, Bias: 0.5703\n",
            "Epoch 607, Loss: 0.1378, Weight: 1.7748, Bias: 0.5699\n",
            "Epoch 608, Loss: 0.1378, Weight: 1.7749, Bias: 0.5695\n",
            "Epoch 609, Loss: 0.1378, Weight: 1.7750, Bias: 0.5691\n",
            "Epoch 610, Loss: 0.1378, Weight: 1.7751, Bias: 0.5688\n",
            "Epoch 611, Loss: 0.1377, Weight: 1.7752, Bias: 0.5684\n",
            "Epoch 612, Loss: 0.1377, Weight: 1.7753, Bias: 0.5680\n",
            "Epoch 613, Loss: 0.1377, Weight: 1.7754, Bias: 0.5676\n",
            "Epoch 614, Loss: 0.1377, Weight: 1.7755, Bias: 0.5672\n",
            "Epoch 615, Loss: 0.1377, Weight: 1.7756, Bias: 0.5669\n",
            "Epoch 616, Loss: 0.1377, Weight: 1.7758, Bias: 0.5665\n",
            "Epoch 617, Loss: 0.1377, Weight: 1.7759, Bias: 0.5661\n",
            "Epoch 618, Loss: 0.1376, Weight: 1.7760, Bias: 0.5657\n",
            "Epoch 619, Loss: 0.1376, Weight: 1.7761, Bias: 0.5654\n",
            "Epoch 620, Loss: 0.1376, Weight: 1.7762, Bias: 0.5650\n",
            "Epoch 621, Loss: 0.1376, Weight: 1.7763, Bias: 0.5646\n",
            "Epoch 622, Loss: 0.1376, Weight: 1.7764, Bias: 0.5643\n",
            "Epoch 623, Loss: 0.1376, Weight: 1.7765, Bias: 0.5639\n",
            "Epoch 624, Loss: 0.1376, Weight: 1.7766, Bias: 0.5635\n",
            "Epoch 625, Loss: 0.1375, Weight: 1.7767, Bias: 0.5632\n",
            "Epoch 626, Loss: 0.1375, Weight: 1.7768, Bias: 0.5628\n",
            "Epoch 627, Loss: 0.1375, Weight: 1.7769, Bias: 0.5624\n",
            "Epoch 628, Loss: 0.1375, Weight: 1.7770, Bias: 0.5621\n",
            "Epoch 629, Loss: 0.1375, Weight: 1.7771, Bias: 0.5617\n",
            "Epoch 630, Loss: 0.1375, Weight: 1.7772, Bias: 0.5613\n",
            "Epoch 631, Loss: 0.1374, Weight: 1.7773, Bias: 0.5610\n",
            "Epoch 632, Loss: 0.1374, Weight: 1.7774, Bias: 0.5606\n",
            "Epoch 633, Loss: 0.1374, Weight: 1.7775, Bias: 0.5603\n",
            "Epoch 634, Loss: 0.1374, Weight: 1.7776, Bias: 0.5599\n",
            "Epoch 635, Loss: 0.1374, Weight: 1.7777, Bias: 0.5595\n",
            "Epoch 636, Loss: 0.1374, Weight: 1.7778, Bias: 0.5592\n",
            "Epoch 637, Loss: 0.1374, Weight: 1.7779, Bias: 0.5588\n",
            "Epoch 638, Loss: 0.1374, Weight: 1.7780, Bias: 0.5585\n",
            "Epoch 639, Loss: 0.1373, Weight: 1.7781, Bias: 0.5581\n",
            "Epoch 640, Loss: 0.1373, Weight: 1.7782, Bias: 0.5578\n",
            "Epoch 641, Loss: 0.1373, Weight: 1.7783, Bias: 0.5574\n",
            "Epoch 642, Loss: 0.1373, Weight: 1.7784, Bias: 0.5571\n",
            "Epoch 643, Loss: 0.1373, Weight: 1.7785, Bias: 0.5567\n",
            "Epoch 644, Loss: 0.1373, Weight: 1.7786, Bias: 0.5564\n",
            "Epoch 645, Loss: 0.1373, Weight: 1.7787, Bias: 0.5560\n",
            "Epoch 646, Loss: 0.1372, Weight: 1.7788, Bias: 0.5557\n",
            "Epoch 647, Loss: 0.1372, Weight: 1.7789, Bias: 0.5553\n",
            "Epoch 648, Loss: 0.1372, Weight: 1.7790, Bias: 0.5550\n",
            "Epoch 649, Loss: 0.1372, Weight: 1.7791, Bias: 0.5547\n",
            "Epoch 650, Loss: 0.1372, Weight: 1.7792, Bias: 0.5543\n",
            "Epoch 651, Loss: 0.1372, Weight: 1.7793, Bias: 0.5540\n",
            "Epoch 652, Loss: 0.1372, Weight: 1.7794, Bias: 0.5536\n",
            "Epoch 653, Loss: 0.1372, Weight: 1.7795, Bias: 0.5533\n",
            "Epoch 654, Loss: 0.1371, Weight: 1.7796, Bias: 0.5530\n",
            "Epoch 655, Loss: 0.1371, Weight: 1.7797, Bias: 0.5526\n",
            "Epoch 656, Loss: 0.1371, Weight: 1.7798, Bias: 0.5523\n",
            "Epoch 657, Loss: 0.1371, Weight: 1.7799, Bias: 0.5520\n",
            "Epoch 658, Loss: 0.1371, Weight: 1.7800, Bias: 0.5516\n",
            "Epoch 659, Loss: 0.1371, Weight: 1.7801, Bias: 0.5513\n",
            "Epoch 660, Loss: 0.1371, Weight: 1.7802, Bias: 0.5510\n",
            "Epoch 661, Loss: 0.1371, Weight: 1.7803, Bias: 0.5506\n",
            "Epoch 662, Loss: 0.1370, Weight: 1.7804, Bias: 0.5503\n",
            "Epoch 663, Loss: 0.1370, Weight: 1.7805, Bias: 0.5500\n",
            "Epoch 664, Loss: 0.1370, Weight: 1.7806, Bias: 0.5496\n",
            "Epoch 665, Loss: 0.1370, Weight: 1.7807, Bias: 0.5493\n",
            "Epoch 666, Loss: 0.1370, Weight: 1.7808, Bias: 0.5490\n",
            "Epoch 667, Loss: 0.1370, Weight: 1.7809, Bias: 0.5487\n",
            "Epoch 668, Loss: 0.1370, Weight: 1.7809, Bias: 0.5483\n",
            "Epoch 669, Loss: 0.1370, Weight: 1.7810, Bias: 0.5480\n",
            "Epoch 670, Loss: 0.1370, Weight: 1.7811, Bias: 0.5477\n",
            "Epoch 671, Loss: 0.1369, Weight: 1.7812, Bias: 0.5474\n",
            "Epoch 672, Loss: 0.1369, Weight: 1.7813, Bias: 0.5470\n",
            "Epoch 673, Loss: 0.1369, Weight: 1.7814, Bias: 0.5467\n",
            "Epoch 674, Loss: 0.1369, Weight: 1.7815, Bias: 0.5464\n",
            "Epoch 675, Loss: 0.1369, Weight: 1.7816, Bias: 0.5461\n",
            "Epoch 676, Loss: 0.1369, Weight: 1.7817, Bias: 0.5458\n",
            "Epoch 677, Loss: 0.1369, Weight: 1.7818, Bias: 0.5455\n",
            "Epoch 678, Loss: 0.1369, Weight: 1.7819, Bias: 0.5451\n",
            "Epoch 679, Loss: 0.1369, Weight: 1.7820, Bias: 0.5448\n",
            "Epoch 680, Loss: 0.1368, Weight: 1.7820, Bias: 0.5445\n",
            "Epoch 681, Loss: 0.1368, Weight: 1.7821, Bias: 0.5442\n",
            "Epoch 682, Loss: 0.1368, Weight: 1.7822, Bias: 0.5439\n",
            "Epoch 683, Loss: 0.1368, Weight: 1.7823, Bias: 0.5436\n",
            "Epoch 684, Loss: 0.1368, Weight: 1.7824, Bias: 0.5433\n",
            "Epoch 685, Loss: 0.1368, Weight: 1.7825, Bias: 0.5430\n",
            "Epoch 686, Loss: 0.1368, Weight: 1.7826, Bias: 0.5426\n",
            "Epoch 687, Loss: 0.1368, Weight: 1.7827, Bias: 0.5423\n",
            "Epoch 688, Loss: 0.1368, Weight: 1.7827, Bias: 0.5420\n",
            "Epoch 689, Loss: 0.1368, Weight: 1.7828, Bias: 0.5417\n",
            "Epoch 690, Loss: 0.1367, Weight: 1.7829, Bias: 0.5414\n",
            "Epoch 691, Loss: 0.1367, Weight: 1.7830, Bias: 0.5411\n",
            "Epoch 692, Loss: 0.1367, Weight: 1.7831, Bias: 0.5408\n",
            "Epoch 693, Loss: 0.1367, Weight: 1.7832, Bias: 0.5405\n",
            "Epoch 694, Loss: 0.1367, Weight: 1.7833, Bias: 0.5402\n",
            "Epoch 695, Loss: 0.1367, Weight: 1.7834, Bias: 0.5399\n",
            "Epoch 696, Loss: 0.1367, Weight: 1.7834, Bias: 0.5396\n",
            "Epoch 697, Loss: 0.1367, Weight: 1.7835, Bias: 0.5393\n",
            "Epoch 698, Loss: 0.1367, Weight: 1.7836, Bias: 0.5390\n",
            "Epoch 699, Loss: 0.1367, Weight: 1.7837, Bias: 0.5387\n",
            "Epoch 700, Loss: 0.1366, Weight: 1.7838, Bias: 0.5384\n",
            "Epoch 701, Loss: 0.1366, Weight: 1.7839, Bias: 0.5381\n",
            "Epoch 702, Loss: 0.1366, Weight: 1.7839, Bias: 0.5378\n",
            "Epoch 703, Loss: 0.1366, Weight: 1.7840, Bias: 0.5375\n",
            "Epoch 704, Loss: 0.1366, Weight: 1.7841, Bias: 0.5372\n",
            "Epoch 705, Loss: 0.1366, Weight: 1.7842, Bias: 0.5370\n",
            "Epoch 706, Loss: 0.1366, Weight: 1.7843, Bias: 0.5367\n",
            "Epoch 707, Loss: 0.1366, Weight: 1.7844, Bias: 0.5364\n",
            "Epoch 708, Loss: 0.1366, Weight: 1.7844, Bias: 0.5361\n",
            "Epoch 709, Loss: 0.1366, Weight: 1.7845, Bias: 0.5358\n",
            "Epoch 710, Loss: 0.1366, Weight: 1.7846, Bias: 0.5355\n",
            "Epoch 711, Loss: 0.1365, Weight: 1.7847, Bias: 0.5352\n",
            "Epoch 712, Loss: 0.1365, Weight: 1.7848, Bias: 0.5349\n",
            "Epoch 713, Loss: 0.1365, Weight: 1.7849, Bias: 0.5347\n",
            "Epoch 714, Loss: 0.1365, Weight: 1.7849, Bias: 0.5344\n",
            "Epoch 715, Loss: 0.1365, Weight: 1.7850, Bias: 0.5341\n",
            "Epoch 716, Loss: 0.1365, Weight: 1.7851, Bias: 0.5338\n",
            "Epoch 717, Loss: 0.1365, Weight: 1.7852, Bias: 0.5335\n",
            "Epoch 718, Loss: 0.1365, Weight: 1.7853, Bias: 0.5332\n",
            "Epoch 719, Loss: 0.1365, Weight: 1.7853, Bias: 0.5330\n",
            "Epoch 720, Loss: 0.1365, Weight: 1.7854, Bias: 0.5327\n",
            "Epoch 721, Loss: 0.1365, Weight: 1.7855, Bias: 0.5324\n",
            "Epoch 722, Loss: 0.1364, Weight: 1.7856, Bias: 0.5321\n",
            "Epoch 723, Loss: 0.1364, Weight: 1.7857, Bias: 0.5318\n",
            "Epoch 724, Loss: 0.1364, Weight: 1.7857, Bias: 0.5316\n",
            "Epoch 725, Loss: 0.1364, Weight: 1.7858, Bias: 0.5313\n",
            "Epoch 726, Loss: 0.1364, Weight: 1.7859, Bias: 0.5310\n",
            "Epoch 727, Loss: 0.1364, Weight: 1.7860, Bias: 0.5307\n",
            "Epoch 728, Loss: 0.1364, Weight: 1.7861, Bias: 0.5305\n",
            "Epoch 729, Loss: 0.1364, Weight: 1.7861, Bias: 0.5302\n",
            "Epoch 730, Loss: 0.1364, Weight: 1.7862, Bias: 0.5299\n",
            "Epoch 731, Loss: 0.1364, Weight: 1.7863, Bias: 0.5297\n",
            "Epoch 732, Loss: 0.1364, Weight: 1.7864, Bias: 0.5294\n",
            "Epoch 733, Loss: 0.1364, Weight: 1.7864, Bias: 0.5291\n",
            "Epoch 734, Loss: 0.1364, Weight: 1.7865, Bias: 0.5288\n",
            "Epoch 735, Loss: 0.1363, Weight: 1.7866, Bias: 0.5286\n",
            "Epoch 736, Loss: 0.1363, Weight: 1.7867, Bias: 0.5283\n",
            "Epoch 737, Loss: 0.1363, Weight: 1.7867, Bias: 0.5280\n",
            "Epoch 738, Loss: 0.1363, Weight: 1.7868, Bias: 0.5278\n",
            "Epoch 739, Loss: 0.1363, Weight: 1.7869, Bias: 0.5275\n",
            "Epoch 740, Loss: 0.1363, Weight: 1.7870, Bias: 0.5272\n",
            "Epoch 741, Loss: 0.1363, Weight: 1.7871, Bias: 0.5270\n",
            "Epoch 742, Loss: 0.1363, Weight: 1.7871, Bias: 0.5267\n",
            "Epoch 743, Loss: 0.1363, Weight: 1.7872, Bias: 0.5265\n",
            "Epoch 744, Loss: 0.1363, Weight: 1.7873, Bias: 0.5262\n",
            "Epoch 745, Loss: 0.1363, Weight: 1.7874, Bias: 0.5259\n",
            "Epoch 746, Loss: 0.1363, Weight: 1.7874, Bias: 0.5257\n",
            "Epoch 747, Loss: 0.1363, Weight: 1.7875, Bias: 0.5254\n",
            "Epoch 748, Loss: 0.1362, Weight: 1.7876, Bias: 0.5252\n",
            "Epoch 749, Loss: 0.1362, Weight: 1.7876, Bias: 0.5249\n",
            "Epoch 750, Loss: 0.1362, Weight: 1.7877, Bias: 0.5246\n",
            "Epoch 751, Loss: 0.1362, Weight: 1.7878, Bias: 0.5244\n",
            "Epoch 752, Loss: 0.1362, Weight: 1.7879, Bias: 0.5241\n",
            "Epoch 753, Loss: 0.1362, Weight: 1.7879, Bias: 0.5239\n",
            "Epoch 754, Loss: 0.1362, Weight: 1.7880, Bias: 0.5236\n",
            "Epoch 755, Loss: 0.1362, Weight: 1.7881, Bias: 0.5234\n",
            "Epoch 756, Loss: 0.1362, Weight: 1.7882, Bias: 0.5231\n",
            "Epoch 757, Loss: 0.1362, Weight: 1.7882, Bias: 0.5229\n",
            "Epoch 758, Loss: 0.1362, Weight: 1.7883, Bias: 0.5226\n",
            "Epoch 759, Loss: 0.1362, Weight: 1.7884, Bias: 0.5224\n",
            "Epoch 760, Loss: 0.1362, Weight: 1.7884, Bias: 0.5221\n",
            "Epoch 761, Loss: 0.1362, Weight: 1.7885, Bias: 0.5219\n",
            "Epoch 762, Loss: 0.1362, Weight: 1.7886, Bias: 0.5216\n",
            "Epoch 763, Loss: 0.1361, Weight: 1.7887, Bias: 0.5214\n",
            "Epoch 764, Loss: 0.1361, Weight: 1.7887, Bias: 0.5211\n",
            "Epoch 765, Loss: 0.1361, Weight: 1.7888, Bias: 0.5209\n",
            "Epoch 766, Loss: 0.1361, Weight: 1.7889, Bias: 0.5206\n",
            "Epoch 767, Loss: 0.1361, Weight: 1.7889, Bias: 0.5204\n",
            "Epoch 768, Loss: 0.1361, Weight: 1.7890, Bias: 0.5201\n",
            "Epoch 769, Loss: 0.1361, Weight: 1.7891, Bias: 0.5199\n",
            "Epoch 770, Loss: 0.1361, Weight: 1.7891, Bias: 0.5197\n",
            "Epoch 771, Loss: 0.1361, Weight: 1.7892, Bias: 0.5194\n",
            "Epoch 772, Loss: 0.1361, Weight: 1.7893, Bias: 0.5192\n",
            "Epoch 773, Loss: 0.1361, Weight: 1.7894, Bias: 0.5189\n",
            "Epoch 774, Loss: 0.1361, Weight: 1.7894, Bias: 0.5187\n",
            "Epoch 775, Loss: 0.1361, Weight: 1.7895, Bias: 0.5185\n",
            "Epoch 776, Loss: 0.1361, Weight: 1.7896, Bias: 0.5182\n",
            "Epoch 777, Loss: 0.1361, Weight: 1.7896, Bias: 0.5180\n",
            "Epoch 778, Loss: 0.1360, Weight: 1.7897, Bias: 0.5177\n",
            "Epoch 779, Loss: 0.1360, Weight: 1.7898, Bias: 0.5175\n",
            "Epoch 780, Loss: 0.1360, Weight: 1.7898, Bias: 0.5173\n",
            "Epoch 781, Loss: 0.1360, Weight: 1.7899, Bias: 0.5170\n",
            "Epoch 782, Loss: 0.1360, Weight: 1.7900, Bias: 0.5168\n",
            "Epoch 783, Loss: 0.1360, Weight: 1.7900, Bias: 0.5166\n",
            "Epoch 784, Loss: 0.1360, Weight: 1.7901, Bias: 0.5163\n",
            "Epoch 785, Loss: 0.1360, Weight: 1.7902, Bias: 0.5161\n",
            "Epoch 786, Loss: 0.1360, Weight: 1.7902, Bias: 0.5159\n",
            "Epoch 787, Loss: 0.1360, Weight: 1.7903, Bias: 0.5156\n",
            "Epoch 788, Loss: 0.1360, Weight: 1.7904, Bias: 0.5154\n",
            "Epoch 789, Loss: 0.1360, Weight: 1.7904, Bias: 0.5152\n",
            "Epoch 790, Loss: 0.1360, Weight: 1.7905, Bias: 0.5149\n",
            "Epoch 791, Loss: 0.1360, Weight: 1.7906, Bias: 0.5147\n",
            "Epoch 792, Loss: 0.1360, Weight: 1.7906, Bias: 0.5145\n",
            "Epoch 793, Loss: 0.1360, Weight: 1.7907, Bias: 0.5143\n",
            "Epoch 794, Loss: 0.1360, Weight: 1.7908, Bias: 0.5140\n",
            "Epoch 795, Loss: 0.1359, Weight: 1.7908, Bias: 0.5138\n",
            "Epoch 796, Loss: 0.1359, Weight: 1.7909, Bias: 0.5136\n",
            "Epoch 797, Loss: 0.1359, Weight: 1.7909, Bias: 0.5134\n",
            "Epoch 798, Loss: 0.1359, Weight: 1.7910, Bias: 0.5131\n",
            "Epoch 799, Loss: 0.1359, Weight: 1.7911, Bias: 0.5129\n",
            "Epoch 800, Loss: 0.1359, Weight: 1.7911, Bias: 0.5127\n",
            "Epoch 801, Loss: 0.1359, Weight: 1.7912, Bias: 0.5125\n",
            "Epoch 802, Loss: 0.1359, Weight: 1.7913, Bias: 0.5122\n",
            "Epoch 803, Loss: 0.1359, Weight: 1.7913, Bias: 0.5120\n",
            "Epoch 804, Loss: 0.1359, Weight: 1.7914, Bias: 0.5118\n",
            "Epoch 805, Loss: 0.1359, Weight: 1.7915, Bias: 0.5116\n",
            "Epoch 806, Loss: 0.1359, Weight: 1.7915, Bias: 0.5114\n",
            "Epoch 807, Loss: 0.1359, Weight: 1.7916, Bias: 0.5112\n",
            "Epoch 808, Loss: 0.1359, Weight: 1.7916, Bias: 0.5109\n",
            "Epoch 809, Loss: 0.1359, Weight: 1.7917, Bias: 0.5107\n",
            "Epoch 810, Loss: 0.1359, Weight: 1.7918, Bias: 0.5105\n",
            "Epoch 811, Loss: 0.1359, Weight: 1.7918, Bias: 0.5103\n",
            "Epoch 812, Loss: 0.1359, Weight: 1.7919, Bias: 0.5101\n",
            "Epoch 813, Loss: 0.1359, Weight: 1.7919, Bias: 0.5099\n",
            "Epoch 814, Loss: 0.1358, Weight: 1.7920, Bias: 0.5096\n",
            "Epoch 815, Loss: 0.1358, Weight: 1.7921, Bias: 0.5094\n",
            "Epoch 816, Loss: 0.1358, Weight: 1.7921, Bias: 0.5092\n",
            "Epoch 817, Loss: 0.1358, Weight: 1.7922, Bias: 0.5090\n",
            "Epoch 818, Loss: 0.1358, Weight: 1.7923, Bias: 0.5088\n",
            "Epoch 819, Loss: 0.1358, Weight: 1.7923, Bias: 0.5086\n",
            "Epoch 820, Loss: 0.1358, Weight: 1.7924, Bias: 0.5084\n",
            "Epoch 821, Loss: 0.1358, Weight: 1.7924, Bias: 0.5082\n",
            "Epoch 822, Loss: 0.1358, Weight: 1.7925, Bias: 0.5079\n",
            "Epoch 823, Loss: 0.1358, Weight: 1.7926, Bias: 0.5077\n",
            "Epoch 824, Loss: 0.1358, Weight: 1.7926, Bias: 0.5075\n",
            "Epoch 825, Loss: 0.1358, Weight: 1.7927, Bias: 0.5073\n",
            "Epoch 826, Loss: 0.1358, Weight: 1.7927, Bias: 0.5071\n",
            "Epoch 827, Loss: 0.1358, Weight: 1.7928, Bias: 0.5069\n",
            "Epoch 828, Loss: 0.1358, Weight: 1.7928, Bias: 0.5067\n",
            "Epoch 829, Loss: 0.1358, Weight: 1.7929, Bias: 0.5065\n",
            "Epoch 830, Loss: 0.1358, Weight: 1.7930, Bias: 0.5063\n",
            "Epoch 831, Loss: 0.1358, Weight: 1.7930, Bias: 0.5061\n",
            "Epoch 832, Loss: 0.1358, Weight: 1.7931, Bias: 0.5059\n",
            "Epoch 833, Loss: 0.1358, Weight: 1.7931, Bias: 0.5057\n",
            "Epoch 834, Loss: 0.1358, Weight: 1.7932, Bias: 0.5055\n",
            "Epoch 835, Loss: 0.1358, Weight: 1.7933, Bias: 0.5053\n",
            "Epoch 836, Loss: 0.1357, Weight: 1.7933, Bias: 0.5051\n",
            "Epoch 837, Loss: 0.1357, Weight: 1.7934, Bias: 0.5049\n",
            "Epoch 838, Loss: 0.1357, Weight: 1.7934, Bias: 0.5047\n",
            "Epoch 839, Loss: 0.1357, Weight: 1.7935, Bias: 0.5045\n",
            "Epoch 840, Loss: 0.1357, Weight: 1.7935, Bias: 0.5043\n",
            "Epoch 841, Loss: 0.1357, Weight: 1.7936, Bias: 0.5041\n",
            "Epoch 842, Loss: 0.1357, Weight: 1.7937, Bias: 0.5039\n",
            "Epoch 843, Loss: 0.1357, Weight: 1.7937, Bias: 0.5037\n",
            "Epoch 844, Loss: 0.1357, Weight: 1.7938, Bias: 0.5035\n",
            "Epoch 845, Loss: 0.1357, Weight: 1.7938, Bias: 0.5033\n",
            "Epoch 846, Loss: 0.1357, Weight: 1.7939, Bias: 0.5031\n",
            "Epoch 847, Loss: 0.1357, Weight: 1.7939, Bias: 0.5029\n",
            "Epoch 848, Loss: 0.1357, Weight: 1.7940, Bias: 0.5027\n",
            "Epoch 849, Loss: 0.1357, Weight: 1.7940, Bias: 0.5025\n",
            "Epoch 850, Loss: 0.1357, Weight: 1.7941, Bias: 0.5023\n",
            "Epoch 851, Loss: 0.1357, Weight: 1.7942, Bias: 0.5021\n",
            "Epoch 852, Loss: 0.1357, Weight: 1.7942, Bias: 0.5019\n",
            "Epoch 853, Loss: 0.1357, Weight: 1.7943, Bias: 0.5018\n",
            "Epoch 854, Loss: 0.1357, Weight: 1.7943, Bias: 0.5016\n",
            "Epoch 855, Loss: 0.1357, Weight: 1.7944, Bias: 0.5014\n",
            "Epoch 856, Loss: 0.1357, Weight: 1.7944, Bias: 0.5012\n",
            "Epoch 857, Loss: 0.1357, Weight: 1.7945, Bias: 0.5010\n",
            "Epoch 858, Loss: 0.1357, Weight: 1.7945, Bias: 0.5008\n",
            "Epoch 859, Loss: 0.1357, Weight: 1.7946, Bias: 0.5006\n",
            "Epoch 860, Loss: 0.1356, Weight: 1.7946, Bias: 0.5004\n",
            "Epoch 861, Loss: 0.1356, Weight: 1.7947, Bias: 0.5002\n",
            "Epoch 862, Loss: 0.1356, Weight: 1.7948, Bias: 0.5001\n",
            "Epoch 863, Loss: 0.1356, Weight: 1.7948, Bias: 0.4999\n",
            "Epoch 864, Loss: 0.1356, Weight: 1.7949, Bias: 0.4997\n",
            "Epoch 865, Loss: 0.1356, Weight: 1.7949, Bias: 0.4995\n",
            "Epoch 866, Loss: 0.1356, Weight: 1.7950, Bias: 0.4993\n",
            "Epoch 867, Loss: 0.1356, Weight: 1.7950, Bias: 0.4991\n",
            "Epoch 868, Loss: 0.1356, Weight: 1.7951, Bias: 0.4989\n",
            "Epoch 869, Loss: 0.1356, Weight: 1.7951, Bias: 0.4988\n",
            "Epoch 870, Loss: 0.1356, Weight: 1.7952, Bias: 0.4986\n",
            "Epoch 871, Loss: 0.1356, Weight: 1.7952, Bias: 0.4984\n",
            "Epoch 872, Loss: 0.1356, Weight: 1.7953, Bias: 0.4982\n",
            "Epoch 873, Loss: 0.1356, Weight: 1.7953, Bias: 0.4980\n",
            "Epoch 874, Loss: 0.1356, Weight: 1.7954, Bias: 0.4979\n",
            "Epoch 875, Loss: 0.1356, Weight: 1.7954, Bias: 0.4977\n",
            "Epoch 876, Loss: 0.1356, Weight: 1.7955, Bias: 0.4975\n",
            "Epoch 877, Loss: 0.1356, Weight: 1.7955, Bias: 0.4973\n",
            "Epoch 878, Loss: 0.1356, Weight: 1.7956, Bias: 0.4971\n",
            "Epoch 879, Loss: 0.1356, Weight: 1.7956, Bias: 0.4970\n",
            "Epoch 880, Loss: 0.1356, Weight: 1.7957, Bias: 0.4968\n",
            "Epoch 881, Loss: 0.1356, Weight: 1.7957, Bias: 0.4966\n",
            "Epoch 882, Loss: 0.1356, Weight: 1.7958, Bias: 0.4964\n",
            "Epoch 883, Loss: 0.1356, Weight: 1.7958, Bias: 0.4963\n",
            "Epoch 884, Loss: 0.1356, Weight: 1.7959, Bias: 0.4961\n",
            "Epoch 885, Loss: 0.1356, Weight: 1.7959, Bias: 0.4959\n",
            "Epoch 886, Loss: 0.1356, Weight: 1.7960, Bias: 0.4957\n",
            "Epoch 887, Loss: 0.1356, Weight: 1.7960, Bias: 0.4956\n",
            "Epoch 888, Loss: 0.1356, Weight: 1.7961, Bias: 0.4954\n",
            "Epoch 889, Loss: 0.1355, Weight: 1.7961, Bias: 0.4952\n",
            "Epoch 890, Loss: 0.1355, Weight: 1.7962, Bias: 0.4950\n",
            "Epoch 891, Loss: 0.1355, Weight: 1.7962, Bias: 0.4949\n",
            "Epoch 892, Loss: 0.1355, Weight: 1.7963, Bias: 0.4947\n",
            "Epoch 893, Loss: 0.1355, Weight: 1.7963, Bias: 0.4945\n",
            "Epoch 894, Loss: 0.1355, Weight: 1.7964, Bias: 0.4944\n",
            "Epoch 895, Loss: 0.1355, Weight: 1.7964, Bias: 0.4942\n",
            "Epoch 896, Loss: 0.1355, Weight: 1.7965, Bias: 0.4940\n",
            "Epoch 897, Loss: 0.1355, Weight: 1.7965, Bias: 0.4938\n",
            "Epoch 898, Loss: 0.1355, Weight: 1.7966, Bias: 0.4937\n",
            "Epoch 899, Loss: 0.1355, Weight: 1.7966, Bias: 0.4935\n",
            "Epoch 900, Loss: 0.1355, Weight: 1.7967, Bias: 0.4933\n",
            "Epoch 901, Loss: 0.1355, Weight: 1.7967, Bias: 0.4932\n",
            "Epoch 902, Loss: 0.1355, Weight: 1.7968, Bias: 0.4930\n",
            "Epoch 903, Loss: 0.1355, Weight: 1.7968, Bias: 0.4928\n",
            "Epoch 904, Loss: 0.1355, Weight: 1.7969, Bias: 0.4927\n",
            "Epoch 905, Loss: 0.1355, Weight: 1.7969, Bias: 0.4925\n",
            "Epoch 906, Loss: 0.1355, Weight: 1.7970, Bias: 0.4923\n",
            "Epoch 907, Loss: 0.1355, Weight: 1.7970, Bias: 0.4922\n",
            "Epoch 908, Loss: 0.1355, Weight: 1.7970, Bias: 0.4920\n",
            "Epoch 909, Loss: 0.1355, Weight: 1.7971, Bias: 0.4919\n",
            "Epoch 910, Loss: 0.1355, Weight: 1.7971, Bias: 0.4917\n",
            "Epoch 911, Loss: 0.1355, Weight: 1.7972, Bias: 0.4915\n",
            "Epoch 912, Loss: 0.1355, Weight: 1.7972, Bias: 0.4914\n",
            "Epoch 913, Loss: 0.1355, Weight: 1.7973, Bias: 0.4912\n",
            "Epoch 914, Loss: 0.1355, Weight: 1.7973, Bias: 0.4910\n",
            "Epoch 915, Loss: 0.1355, Weight: 1.7974, Bias: 0.4909\n",
            "Epoch 916, Loss: 0.1355, Weight: 1.7974, Bias: 0.4907\n",
            "Epoch 917, Loss: 0.1355, Weight: 1.7975, Bias: 0.4906\n",
            "Epoch 918, Loss: 0.1355, Weight: 1.7975, Bias: 0.4904\n",
            "Epoch 919, Loss: 0.1355, Weight: 1.7976, Bias: 0.4902\n",
            "Epoch 920, Loss: 0.1355, Weight: 1.7976, Bias: 0.4901\n",
            "Epoch 921, Loss: 0.1355, Weight: 1.7976, Bias: 0.4899\n",
            "Epoch 922, Loss: 0.1354, Weight: 1.7977, Bias: 0.4898\n",
            "Epoch 923, Loss: 0.1354, Weight: 1.7977, Bias: 0.4896\n",
            "Epoch 924, Loss: 0.1354, Weight: 1.7978, Bias: 0.4895\n",
            "Epoch 925, Loss: 0.1354, Weight: 1.7978, Bias: 0.4893\n",
            "Epoch 926, Loss: 0.1354, Weight: 1.7979, Bias: 0.4891\n",
            "Epoch 927, Loss: 0.1354, Weight: 1.7979, Bias: 0.4890\n",
            "Epoch 928, Loss: 0.1354, Weight: 1.7980, Bias: 0.4888\n",
            "Epoch 929, Loss: 0.1354, Weight: 1.7980, Bias: 0.4887\n",
            "Epoch 930, Loss: 0.1354, Weight: 1.7980, Bias: 0.4885\n",
            "Epoch 931, Loss: 0.1354, Weight: 1.7981, Bias: 0.4884\n",
            "Epoch 932, Loss: 0.1354, Weight: 1.7981, Bias: 0.4882\n",
            "Epoch 933, Loss: 0.1354, Weight: 1.7982, Bias: 0.4881\n",
            "Epoch 934, Loss: 0.1354, Weight: 1.7982, Bias: 0.4879\n",
            "Epoch 935, Loss: 0.1354, Weight: 1.7983, Bias: 0.4878\n",
            "Epoch 936, Loss: 0.1354, Weight: 1.7983, Bias: 0.4876\n",
            "Epoch 937, Loss: 0.1354, Weight: 1.7984, Bias: 0.4875\n",
            "Epoch 938, Loss: 0.1354, Weight: 1.7984, Bias: 0.4873\n",
            "Epoch 939, Loss: 0.1354, Weight: 1.7984, Bias: 0.4872\n",
            "Epoch 940, Loss: 0.1354, Weight: 1.7985, Bias: 0.4870\n",
            "Epoch 941, Loss: 0.1354, Weight: 1.7985, Bias: 0.4869\n",
            "Epoch 942, Loss: 0.1354, Weight: 1.7986, Bias: 0.4867\n",
            "Epoch 943, Loss: 0.1354, Weight: 1.7986, Bias: 0.4866\n",
            "Epoch 944, Loss: 0.1354, Weight: 1.7986, Bias: 0.4864\n",
            "Epoch 945, Loss: 0.1354, Weight: 1.7987, Bias: 0.4863\n",
            "Epoch 946, Loss: 0.1354, Weight: 1.7987, Bias: 0.4861\n",
            "Epoch 947, Loss: 0.1354, Weight: 1.7988, Bias: 0.4860\n",
            "Epoch 948, Loss: 0.1354, Weight: 1.7988, Bias: 0.4858\n",
            "Epoch 949, Loss: 0.1354, Weight: 1.7989, Bias: 0.4857\n",
            "Epoch 950, Loss: 0.1354, Weight: 1.7989, Bias: 0.4855\n",
            "Epoch 951, Loss: 0.1354, Weight: 1.7989, Bias: 0.4854\n",
            "Epoch 952, Loss: 0.1354, Weight: 1.7990, Bias: 0.4853\n",
            "Epoch 953, Loss: 0.1354, Weight: 1.7990, Bias: 0.4851\n",
            "Epoch 954, Loss: 0.1354, Weight: 1.7991, Bias: 0.4850\n",
            "Epoch 955, Loss: 0.1354, Weight: 1.7991, Bias: 0.4848\n",
            "Epoch 956, Loss: 0.1354, Weight: 1.7991, Bias: 0.4847\n",
            "Epoch 957, Loss: 0.1354, Weight: 1.7992, Bias: 0.4845\n",
            "Epoch 958, Loss: 0.1354, Weight: 1.7992, Bias: 0.4844\n",
            "Epoch 959, Loss: 0.1354, Weight: 1.7993, Bias: 0.4843\n",
            "Epoch 960, Loss: 0.1354, Weight: 1.7993, Bias: 0.4841\n",
            "Epoch 961, Loss: 0.1354, Weight: 1.7993, Bias: 0.4840\n",
            "Epoch 962, Loss: 0.1354, Weight: 1.7994, Bias: 0.4838\n",
            "Epoch 963, Loss: 0.1354, Weight: 1.7994, Bias: 0.4837\n",
            "Epoch 964, Loss: 0.1353, Weight: 1.7995, Bias: 0.4836\n",
            "Epoch 965, Loss: 0.1353, Weight: 1.7995, Bias: 0.4834\n",
            "Epoch 966, Loss: 0.1353, Weight: 1.7995, Bias: 0.4833\n",
            "Epoch 967, Loss: 0.1353, Weight: 1.7996, Bias: 0.4831\n",
            "Epoch 968, Loss: 0.1353, Weight: 1.7996, Bias: 0.4830\n",
            "Epoch 969, Loss: 0.1353, Weight: 1.7997, Bias: 0.4829\n",
            "Epoch 970, Loss: 0.1353, Weight: 1.7997, Bias: 0.4827\n",
            "Epoch 971, Loss: 0.1353, Weight: 1.7997, Bias: 0.4826\n",
            "Epoch 972, Loss: 0.1353, Weight: 1.7998, Bias: 0.4824\n",
            "Epoch 973, Loss: 0.1353, Weight: 1.7998, Bias: 0.4823\n",
            "Epoch 974, Loss: 0.1353, Weight: 1.7999, Bias: 0.4822\n",
            "Epoch 975, Loss: 0.1353, Weight: 1.7999, Bias: 0.4820\n",
            "Epoch 976, Loss: 0.1353, Weight: 1.7999, Bias: 0.4819\n",
            "Epoch 977, Loss: 0.1353, Weight: 1.8000, Bias: 0.4818\n",
            "Epoch 978, Loss: 0.1353, Weight: 1.8000, Bias: 0.4816\n",
            "Epoch 979, Loss: 0.1353, Weight: 1.8001, Bias: 0.4815\n",
            "Epoch 980, Loss: 0.1353, Weight: 1.8001, Bias: 0.4814\n",
            "Epoch 981, Loss: 0.1353, Weight: 1.8001, Bias: 0.4812\n",
            "Epoch 982, Loss: 0.1353, Weight: 1.8002, Bias: 0.4811\n",
            "Epoch 983, Loss: 0.1353, Weight: 1.8002, Bias: 0.4810\n",
            "Epoch 984, Loss: 0.1353, Weight: 1.8002, Bias: 0.4808\n",
            "Epoch 985, Loss: 0.1353, Weight: 1.8003, Bias: 0.4807\n",
            "Epoch 986, Loss: 0.1353, Weight: 1.8003, Bias: 0.4806\n",
            "Epoch 987, Loss: 0.1353, Weight: 1.8004, Bias: 0.4804\n",
            "Epoch 988, Loss: 0.1353, Weight: 1.8004, Bias: 0.4803\n",
            "Epoch 989, Loss: 0.1353, Weight: 1.8004, Bias: 0.4802\n",
            "Epoch 990, Loss: 0.1353, Weight: 1.8005, Bias: 0.4801\n",
            "Epoch 991, Loss: 0.1353, Weight: 1.8005, Bias: 0.4799\n",
            "Epoch 992, Loss: 0.1353, Weight: 1.8005, Bias: 0.4798\n",
            "Epoch 993, Loss: 0.1353, Weight: 1.8006, Bias: 0.4797\n",
            "Epoch 994, Loss: 0.1353, Weight: 1.8006, Bias: 0.4795\n",
            "Epoch 995, Loss: 0.1353, Weight: 1.8007, Bias: 0.4794\n",
            "Epoch 996, Loss: 0.1353, Weight: 1.8007, Bias: 0.4793\n",
            "Epoch 997, Loss: 0.1353, Weight: 1.8007, Bias: 0.4792\n",
            "Epoch 998, Loss: 0.1353, Weight: 1.8008, Bias: 0.4790\n",
            "Epoch 999, Loss: 0.1353, Weight: 1.8008, Bias: 0.4789\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the neural network\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # One input, one output\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Create the model\n",
        "model = SimpleNet()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Generate training data\n",
        "x_train = torch.tensor([[1.2], [2.5], [3.7], [4.6]])\n",
        "y_train = torch.tensor([[2.4], [5.5], [6.7], [8.9]])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1000):\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print the updated parameters after each epoch\n",
        "    weight = model.linear.weight.item()\n",
        "    bias = model.linear.bias.item()\n",
        "    print(f'Epoch {epoch}, Loss: {loss.item():.4f}, Weight: {weight:.4f}, Bias: {bias:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "x_test = torch.tensor([[[1.2], [2.5], [3.7], [4.6]]])\n",
        "y_pred = model(x_test)\n",
        "\n",
        "print(\"\\nTest results:\")\n",
        "for i in range(len(x_test)):\n",
        "    print(f\"Input: {x_test[i][0][0].item()}, Predicted Output: {y_pred[i][0].item():.4f}, Expected Output: {2*x_test[i][0][0].item()}\")\n",
        "\n",
        "# Print the learned weight and bias\n",
        "print(f\"\\nLearned weight: {model.linear.weight.item():.4f}\")\n",
        "print(f\"Learned bias: {model.linear.bias.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux6iCDalTg50",
        "outputId": "2828dc13-74e0-4f40-cd4d-db1e846a0524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test results:\n",
            "Input: 1.2000000476837158, Predicted Output: 2.6399, Expected Output: 2.4000000953674316\n",
            "\n",
            "Learned weight: 1.8008\n",
            "Learned bias: 0.4789\n"
          ]
        }
      ]
    }
  ]
}